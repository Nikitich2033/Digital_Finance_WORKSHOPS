{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCL\n",
    "\n",
    "## COMP0164 Digital Finance\n",
    "\n",
    "## Workshop 2: Intermediate Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [1. Imports](#1.-Imports)\n",
    "* [2. Object Oriented Programming](#2.-Object-Oriented-Programming)\n",
    "    * [2.1 Attributes](#2.1-Attributes)\n",
    "    * [2.2 Methods](#2.2-Methods)\n",
    "    * [2.3 Common Classes and Methods in Python](#2.3-Common-CLasses-and-Methods-in-Python)\n",
    "        * [2.3.1 Strings (Revisited)](#2.3.1-Strings-(Revisited))\n",
    "        * [2.3.2 Lists (Revisited)](#2.3.2-Lists-(Revisited))\n",
    "    * [2.4 Object Oriented Programming: Exercises](#2.4-Object-Oriented-Programming:-Exercises)\n",
    "* [3. Data  Structures: Pandas](#3.-Data-Structures:-Pandas)\n",
    "    * [3.1 Series](#3.1-Series)\n",
    "    * [3.2 DataFrames](#3.2-DataFrames)\n",
    "    * [3.3 Index Objects](#3.3-Index-Objects)\n",
    "        * [3.3.1 Index Objects: Exercises](#3.3.1-Index-Objects:-Exercises)\n",
    "    * [3.4 Essential Functionality](#3.4-Essential-Functionality)\n",
    "        * [3.4.1 Reindexing](#3.4.1-Reindexing)\n",
    "        * [3.4.2 Dropping Entries from an Axis](#3.4.2-Dropping-Entries-from-an-Axis)\n",
    "    * [3.5 Indexing, Selection, and Filtering](#3.5-Indexing,-Selection,-and-Filtering)\n",
    "        * [3.5.1 Arithmetic and Data Alignment](#3.5.1-Arithmetic-and-Data-Alignment)\n",
    "        * [3.5.2 Function Application and Mapping](#3.5.2-Function-Application-and-Mapping)\n",
    "        * [3.5.3 Sorting and Ranking](#3.5.3-Sorting-and-Ranking)\n",
    "        * [3.5.4 Axis Indexing with Duplicate Values](#3.5.4-Axis-Indexing-with-Duplicate-Values)\n",
    "        * [3.5.5 Indexing, Selection, and Filtering: Exercies](#3.5.5-Indexing,-Selection,-and-Filtering:-Exercises)\n",
    "    * [3.6 Computing Descriptive Statistics](#3.6-Computing-Descriptive-Statistics)\n",
    "        * [3.6.1 Correlation and Covariance](#3.6.1-Correlation-and-Covariance)\n",
    "        * [3.6.2 Unique Values, Value Counts, and Membership](#3.6.2-Unique-Values,-Value-Counts,-and-Membership)\n",
    "    * [3.7 Handling Missing Data](#3.7-Handling-Missing-Data)\n",
    "        * [3.7.1 Filtering Out Missing Data](#3.7.1-FFiltering-Out-Missing-Data)\n",
    "        * [3.7.2 Filling In Missing Data](#3.7.2-Filling-In-Missing-Data)\n",
    "        * [3.7.3 Handling Missing Data: Exercises](#3.7.3-Handling-Missing-Data:-Exercises)\n",
    "    * [3.8 Custom Data Import](#3.8-Custom-Data-Import)\n",
    "    * [3.9 Combining and Merging Data Sets](#3.9-Combining-and-Merging-Data-Sets)\n",
    "        * [3.9.1 Database-Style DataFrame Merges](#3.9.1-Database-Style-`DataFrame`-Merges)\n",
    "        * [3.9.2 Merging on Index](#3.9.2-Merging-on-`Index`)\n",
    "        * [3.9.3 Combining-and-Merging-Datasets: Exercises](#3.9.3-Combining-and-Merging-Data-Sets:-Exercises)\n",
    "    * [3.10 Concatenating Along an Axis](#3.10-Concatenating-Along-an-Axis)\n",
    "    * [3.11 Combining Data with overlap](#3.11-Combining-Data-with-`overlap`)\n",
    "        * [3.11.1 Combining Data with overlap: Exercises](#3.11.1-Combining-Data-with-`overlap`:-Exercises)\n",
    "    * [3.12 Reshaping](#3.12-Reshaping)\n",
    "        * [3.12.1 Reshaping-with-Hierarchical-Indexing](#3.12.1-Reshaping-with-Hieararchical-Indexing)\n",
    "        * [3.12.2 Reshaping: Exercises](#3.12.2-Reshaping:-Exercises)\n",
    "    * [3.13 Data Transformation](#3.13-Data-Transformation)\n",
    "        * [3.13.1 Removing Duplicates](#3.13.1-Removing-Duplicates)\n",
    "        * [3.13.2 Transforming Data Using a Function or Mapping](#3.13.2-Transforming-Data-Using-a-Function-or-Mapping)\n",
    "        * [3.13.3 Data Transformation: Exercises](#3.13.3-Data-Transformation:-Exercises)\n",
    "    * [3.14 Replacing Values](#3.14-Replacing-Values)\n",
    "        * [3.14.1 Renaming Axis Indexes](#3.14.1-Renaming-Axis-Indexes)\n",
    "        * [3.14.2 Discetization and Binning](#3.14.2-Discretization-and-Binning)\n",
    "        * [3.14.3 Detecing and Filtering Outliers](#3.14.3-Detecing-and-Filtering-Outliers)\n",
    "        * [3.14.4 Permutation and Random Sampling](#3.14.4-Permutation-and-Random-Sampling)\n",
    "        * [3.14.5 Replacing Values: Exercises](#3.14.5-Replacing-Values:-Exercises)\n",
    "* [4. APIs and Working with Web Applications](#4.-APIs-and-Working-with-Web-Applications)\n",
    "    * [4.1 Importing Files from the Web](#4.1-Importing-Files-from-the-Web)\n",
    "    * [4.2 HTTP Requests in Python](#4.2-HTTP-Requests-in-Python)\n",
    "        * [4.2.1 HTTP Requests Using requests](#4.2.1-HTTP-Requests-Using-**`requests`**)\n",
    "    * [4.3 API Requests](#4.3-API-Requests)\n",
    "        * [4.3.1 API Requests With Authentication](#4.3.1-API-Requests-With-Authentication)\n",
    "        * [4.3.2 API Requests Without Authentication](#4.3.2-API-Requests-Without-Authentication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports\n",
    "\n",
    "We need to import the following modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interlude: Discount Rates and Cahsflows\n",
    "\n",
    "## Discount Rates\n",
    "\n",
    "<mark>Discount rates</mark> are used to compute <mark>the Net Present Value (NPV)</mark> or the <mark>Present Value (PV)</mark> of the investment opportunity as part of the Discounted Cash Flow (DCF) analysis. [They allow us to](https://corporatefinanceinstitute.com/resources/valuation/discount-rate/):\n",
    "\n",
    "- Account for the time value of money\n",
    "- Account for the riskiness of an investment\n",
    "- Represent opportunity cost for a company\n",
    "- Act as minimum return rate (hurdle rate) for investment decisions\n",
    "- Allow for comparison of different investment projects and strategies\n",
    "\n",
    "Therefore, picking the right discounting rate is crucial for performing the cashflow analysis.\n",
    "\n",
    "The commonly used discount rates in the corporate finance are:\n",
    "\n",
    "- **Cost of Equity**: For calculating the equity value of a company.\n",
    "- **Cost of Debt**: For calculating the value of a bond or fixed-income security.\n",
    "- **Weighted Average Cost of Capital (WACC)**: For calculating the enterprise value of company.\n",
    "- **Hurdle Rate**: For calculating the investment in internal corporate projects.\n",
    "- **Risk-Free Rate**: For calculating the impact of time value of money on an investment or project.\n",
    "\n",
    "## Discounting Cashflows\n",
    "\n",
    "When evaluating investments, we take into considerations cashflows generated as returns but also the costs associated with the investment. Therefore, the <mark>discounting models can be modified to reflect discounted costs</mark> that will be discounted at a certain rate going forward.\n",
    "\n",
    "For example, if there is an administrative cost associated with an annuity-like investment, we can axpress its NPV as:\n",
    "\n",
    "$$NPV_{\\text{modified}} = PV_{\\text{annuity}} - PV_{\\text{cost}} = C[\\frac{1}{r}-\\frac{1}{r(1+r)^{n}}] - H[\\frac{1}{r^{\\prime}}-\\frac{1}{r(1+r^{\\prime})^{n}}],$$\n",
    "\n",
    "where\n",
    "\n",
    "- $C$ is the cash flow of an annuity\n",
    "- $H$ is the cost\n",
    "- $r$ and $r^{\\prime}$ are the discounting rates (they can be different or the same depending on the model)\n",
    "\n",
    "Note, that we can modify NPV and PV in many different ways, depending on the application. Therefore, different rates and timeframes might be used in the same model simultanously.\n",
    "\n",
    "The questions you may want to ask when evaluating the NPV and PV are:\n",
    "\n",
    "- What does the NPV/PV represent in the model (i.e., equity, debt, enterprise value)?\n",
    "- What does each cash flow represent?\n",
    "- What are the discount rates for each cash flow?\n",
    "- What are the time steps at which the cash flows are discounted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Object Oriented Programming\n",
    "\n",
    "**`Python`** uses **Object Oriented Programming (OOP)** paradigm, meaning that we can define 'types' of objects and reuse this definition to create objects of the same type without having to define similar feature over and over again.\n",
    "\n",
    "**OOP** paradigm is based on the concept of objects that contain data and code:\n",
    "\n",
    "- The data describes an object and we usually refer to this data as attributes or properties.\n",
    "- The code is defines the actions that an object can perform, including processing its own data (i.e., attributes). A class can have multiple different bits of code (i.e., functions) and we refer to them as methods.\n",
    "\n",
    "In **`Python`**, we define a class using the `class` keyword.\n",
    "\n",
    "Inside the class we can refer to itself using the keyword `self`, in order to access its own attributes or run its methods.\n",
    "\n",
    "For example, let's say we want to create multiple cars to perform some simulations or do data processing. We assume that a car has a manufacturer and a colour. Also, we want a car to move forward and backward.\n",
    "\n",
    "Instead of rewriting code to create individual cars, we can define a class to do this job for us and include all the relevant information inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car:\n",
    "    has_wheels = True\n",
    "\n",
    "    def __init__(self, manufacturer:str, colour:str) -> None:\n",
    "        self.manufacturer = manufacturer\n",
    "        self.colour = colour\n",
    "\n",
    "    def drive_forward(self, x:float) -> float:\n",
    "        return x+5\n",
    "    \n",
    "    def drive_back(self, x:float) -> float:\n",
    "        return x-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class defines a general template that all cars that we will define will follow.\n",
    "\n",
    "Inside this class we used multiple abstractions:\n",
    "\n",
    "- **Class atribute** is an attribute that every object of this class will have. The **class attributes** are defined in the main body of the class (e.g., `has_wheels` attribute in our example).\n",
    "- **Instance attribute** is an attribute that is specific to every object of this class. **Instance attributes** are defined inside the `.__init__()` method by assigning the input variables to this class using the `self` keyword (e.g., `manufacturer` and `colour` are specific to every car and we assign them inside the `.__init__()` function).\n",
    "- **Method** is a block of code that every instance of the class will have. it is defined in the main body of the class just like we did with functions. The only difference is that we pass `self` keyword as the first parameter in order to notify the class that this method may use some of the class attributes (e.g., `.drive_forward()` and `.drive_back()` are two methods we defined as every car should drive forward and reverse).\n",
    "\n",
    "Now we can use this class to define multiple objects of this class (i.e., instances of this class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_1 = Car(manufacturer=\"BMW\", colour=\"black\")\n",
    "car_2 = Car(manufacturer=\"Ferrari\", colour=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We 'create' an instance or object of the class by calling the class and assigning to it the required instance attributes.\n",
    "\n",
    "In our case, we initiated two objects of type car vy providing the manufacturerr and the colour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Attributes\n",
    "\n",
    "As mentioned above. we can access the data stored inside the classes.\n",
    "\n",
    "In order to do that we use the name of the instance followed by `.` and the name of the instance attribute that we want to get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMW\n",
      "red\n"
     ]
    }
   ],
   "source": [
    "# Example of getting the manufacturer of the car_1\n",
    "print(car_1.manufacturer)\n",
    "\n",
    "# Example of getting the colour of car_2\n",
    "print(car_2.colour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access the class attributes in the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(car_1.has_wheels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Methods\n",
    "\n",
    "Class methods allow us to work with data inside the class or for the objects we define to perform some actions.\n",
    "\n",
    "For example, if `car_1` positioned along the x-axis we can make it go in that direction by calling `.drive_forward()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "print(car_1.drive_forward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proiblem with our current class is that it doesn't store the position of the car. We can change this by adding a new instance attribute to our `.__init__()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "class Car:\n",
    "    def __init__(self, manufacturer:str, colour:str, x:Union[int, float]) -> None:\n",
    "        self.manufacturer = manufacturer\n",
    "        self.colour = colour\n",
    "        self.x = x\n",
    "\n",
    "    def drive_forward(self) -> None:\n",
    "        self.x = self.x+5\n",
    "        return None\n",
    "    \n",
    "    def drive_back(self) -> None:\n",
    "        self.x = self.x-5\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the code above the methods don't anymore require the `x` parameter as we have defined it as the instance attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "car_3 = Car(manufacturer=\"Toyota\", colour=\"white\", x=40)\n",
    "car_3.drive_forward()\n",
    "print(car_3.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Common Classes and Methods in Python\n",
    "\n",
    "We have previously encountered classed as these are widely used in **`Python`** to define objects, including data types (i.e., recall that `type(str)` returns `<class 'str'>`).\n",
    "\n",
    "Class as an abstarction has multiple default methods prebuilt that we can rewdefine for any class:\n",
    "\n",
    "- `.__init__()` method hels us initiate an instance of this class, assigning instance attributed, performing checks and initiation parent classes if these exist.\n",
    "- `.__len__()` method allows us to definethe function that we can use to provide the length of our object. This method will be used when we call `lan(instance)` function of this instance (e.g., if we have a list `some_list`, we can check its length by `len(some_list)`, which will refer to the method `__len__()` inside the `list` type)\n",
    "- `.__str__()` method allows us to print some information about the class when we call the `print()` function over it.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "\n",
    "class Stock:\n",
    "    def __init__(self, ticker:str, current_price:Union[int, float], n_datapoints:int) -> None:\n",
    "        self.ticker = ticker\n",
    "        self.current_price = current_price\n",
    "        self.n_datapoints = n_datapoints\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return self.ticker\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.n_datapoints\n",
    "    \n",
    "apple = Stock(ticker=\"AAPL\", current_price=175.51, n_datapoints=1200)\n",
    "# print() function accesses .__str__() method of the class Stock\n",
    "print(apple)\n",
    "# len() function accesses .__len__() method of the class Stock\n",
    "print(len(apple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Strings (Revisited)\n",
    "\n",
    "We have already introduces strings as a data type, but now we can look at the methods available to objects of string class\n",
    "\n",
    "Some of the common string methods are listed in the table below along with the description of their functionality;\n",
    "| Method | Description |\n",
    "| --- | --- |\n",
    "| `.format()` | Fill in the spaces `{}` inside the string. This way we can create a template of a string and some values to it later. |\n",
    "| `.upper()` | Capitalize all alphabetical characters inside a string |\n",
    "| `.lower()` | Decapitalize all alphabetical characters inside a string |\n",
    "| `.split()` | Given a sequence of characters, we can split the string using these characters into multiple strings |\n",
    "| `.replace()` | Replace certain sequence of characters with a new sequence of characters |\n",
    "| `.find()` | Find an occurance of a certain sequence of characters and returns the index of the first character from the searched sequence in a string |\n",
    "\n",
    "Below are some examples of how to use these methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world! How are you?\n",
      "NO CAPITAL LETTERS\n",
      "some letters are capitalized\n",
      "['String', ' is', ' separated', ' into', ' parts.']\n",
      "['Dogs ', ' cats ', ' whales ', ' tigers are animals.']\n",
      "True or False\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# Example of using .format() method to fill in the missing values inside a string\n",
    "some_string = \"Hello, {0}! How {1} you?\".format(\"world\", \"are\")\n",
    "print(some_string)\n",
    "\n",
    "#Example of using .upper() method to capitalize all letters in a string\n",
    "some_string = \"no capital letters\".upper()\n",
    "print(some_string)\n",
    "\n",
    "# Example of using .lower() method to decapitalize all letters in a string\n",
    "some_string = \"Some letters are CAPITALIZED\".lower()\n",
    "print(some_string)\n",
    "\n",
    "# Example of using .split() method to sptil a string based on symbol ;\n",
    "some_string = \"String; is; separated; into; parts.\".split(\";\")\n",
    "print(some_string)\n",
    "\n",
    "# Example of using .split() method to sptil a string based on a sequence of characters \"and\"\n",
    "some_string = \"Dogs and cats and whales and tigers are animals.\".split(\"and\")\n",
    "print(some_string)\n",
    "\n",
    "# Example of using .replace() method to replace certain part of a string\n",
    "some_string = \"True and False\".replace(\"and\", \"or\")\n",
    "print(some_string)\n",
    "\n",
    "# Example of using .find() method to search for a certain part of a string\n",
    "some_string = \"These are not the droids you are looking for.\".find(\"droids\")\n",
    "print(some_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>TIP: </b>Note that .split() method will split the string based on spaces if no argument is provided.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are just a few string methods that are available to us in **`Python`**, you can see all of them in **`Python`**'s documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Lists (Revisited)\n",
    "\n",
    "Similarly to strings, lists also have some inbuild methods that allow us to perform data manipulation.\n",
    "\n",
    "Some common list methods are defined in the table below:\n",
    "\n",
    "| Method | Description |\n",
    "| --- | --- |\n",
    "| `.append()` | Add an element on the end of a list |\n",
    "| `.extend()` | Add multiple iterative elements on ther end of a list |\n",
    "| `.insert()` | Insert an element into list at a given index and shuffle other elements by an index |\n",
    "| `.copy()` | Create a copy of a list |\n",
    "| `.remove()` | Delete an element of a list |\n",
    "| `.pop()` | Return a specific element from a list while simultaneously removing it from the list |\n",
    "| `.index` | Return an index of an element in a list |\n",
    "\n",
    "Below are some examples of how we can apply these methods to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 45, 'world', 78.3, 'new element']\n",
      "['Hello', 45, 'world', 78.3, 'new', 'elements']\n",
      "['Hello', 45, 'new element', 'world', 78.3]\n",
      "['Hello', 45, 'world', 78.3]\n",
      "[45, 'world', 78.3]\n",
      "['Hello', 45, 78.3] \t world\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Example of using .append() method to add an element to the end of the list\n",
    "some_list = [\"Hello\", 45, \"world\", 78.3]\n",
    "some_list.append(\"new element\")\n",
    "print(some_list)\n",
    "\n",
    "# Example of using .extend() method to add multiple elements to the list\n",
    "some_list = [\"Hello\", 45, \"world\", 78.3]\n",
    "some_list.extend([\"new\", \"elements\"])\n",
    "print(some_list)\n",
    "\n",
    "# Example of using .insert() method to add an element to the list at the predifeined index\n",
    "some_list = [\"Hello\", 45, \"world\", 78.3]\n",
    "some_list.insert(2, \"new element\")\n",
    "print(some_list)\n",
    "\n",
    "# Example of using .copy() method\n",
    "some_list = [\"Hello\", 45, \"world\", 78.3]\n",
    "new_list = some_list.copy()\n",
    "print(some_list)\n",
    "\n",
    "# Example of using .remove() method to delete an element of the list\n",
    "some_list = [\"Hello\", 45, \"world\", 78.3]\n",
    "some_list.remove(\"Hello\")\n",
    "print(some_list)\n",
    "\n",
    "# Example of using .pop()\n",
    "some_list = [\"Hello\", 45, \"world\", 78.3]\n",
    "item = some_list.pop(2)\n",
    "print(some_list, \"\\t\", item)\n",
    "\n",
    "# Example of using .index method to get an index of an element in the list\n",
    "some_list = [\"Hello\", 45, \"world\", 78.3]\n",
    "print(some_list.index(\"world\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Object Oriented Programming: Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (1)</b>\n",
    "<br>\n",
    "\n",
    "From the first lecture you have seen that the present value of a coupon bond is given by the equatioon:\n",
    "$$PV = c[\\frac{1}{r}-\\frac{1}{r(1+r)^{n}}]+\\frac{P}{(1+r)^{n}},$$\n",
    "where <b>P</b> is the principal, <b>c</b> is the coupon, <b>r</b> is the discount rate, and <b>n</b> is the number of time periods.\n",
    "\n",
    "Write a class <b>CouponBond</b> that takes these four arguments as instance arguments and write a method called <b>present_value</b> that computes the present value of the coupon bond.\n",
    "\n",
    "Optionally, implement a method that would return <b>n</b> when you use the function <b>len()</b> on the instance of the bond.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Structures: Pandas\n",
    "\n",
    "**`Pandas`** is a package that allows us to work with data leveraging the speed of **`C`** and **`NumPy`**.\n",
    "\n",
    "Inside **`Pandas`** there are two commonly used data structures:\n",
    "\n",
    "- `Series` is a one-dimensional array-like object containing an array of data (of any **`NumPy`** data type) and an assocciated array of data labels, called an `index`.\n",
    "- `DataFrame` is a tabular, spreadsheet-like data structure that containing an ordered collection of columns each of which can be a different data type (e.g., numeric, string, boolean)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Series\n",
    "\n",
    "A `Series` is constructed using a `Series` keyword, but it requires us to import it from **`Pandas`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "series = pd.Series([1, 2, 3, 4])\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also provide an index to Series to label our data using the `index` keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "series = pd.Series([1, 2, 3, 4], index=[\"a\", \"b\", \"c\", \"d\"])\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the array representation and index of the Series via `.value` and `.index` attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "Index(['a', 'b', 'c', 'd'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(series.values)\n",
    "print(series.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared with a regular **`NumPy`** array, you can use values in the index when selecting single values or a set of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "c    3\n",
       "a    1\n",
       "d    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(series['a'])\n",
    "series['d'] = 6\n",
    "series[['c', 'a', 'd']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform filtering on `Series`. To do this we need to provovide an array of boolean values as its index.\n",
    "\n",
    "In order to obtain an array of booleans that satisfy a condition we can use Series inside the conditional statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    6\n",
      "dtype: int64\n",
      "a    False\n",
      "b     True\n",
      "c     True\n",
      "d     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(series)\n",
    "print(series>1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use this conditional statement to filter the `Series`, as only the row where `True` is returned will be visible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    6\n",
      "dtype: int64\n",
      "b    2\n",
      "c    3\n",
      "d    6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(series)\n",
    "print(series[series > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform **`NumPy`** operations on the series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a     2\n",
      "b     4\n",
      "c     6\n",
      "d    12\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a      2.718282\n",
       "b      7.389056\n",
       "c     20.085537\n",
       "d    403.428793\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(series*2)\n",
    "np.exp(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to think about a `Series` is as a fixed-length, ordered dict, as it is a mapping of index values to data values. \n",
    "\n",
    "It can be substituted into many functions that expect a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print('b' in series)\n",
    "print('e' in series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should you have data contained in a dictionary, you can create a `Series` from it by passing the dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ohio      35000\n",
      "Texas     71000\n",
      "Oregon    16000\n",
      "Utah       5000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000}\n",
    "series = pd.Series(sdata)\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When only passing a dictionary, the index in the resulting `Series` will have the dictionary’s keys in sorted order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California        NaN\n",
      "Ohio          35000.0\n",
      "Oregon        16000.0\n",
      "Texas         71000.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "states = ['California', 'Ohio', 'Oregon', 'Texas']\n",
    "series = pd.Series(sdata, index=states)\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, 3 values found in `sdata` were placed in the appropriate locations, but since no value for 'California' was found, it appears as `NaN` (*not a number*) which is considered in **`Pandas`** to mark missing or *NA* values. We will use the terms “missing” or “NA” to refer to missing data. \n",
    "\n",
    "The `.isnull()` and `.notnull()` methods in **`Pandas`** should be used to detect missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California     True\n",
       "Ohio          False\n",
       "Oregon        False\n",
       "Texas         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Series` also has these as instance methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California     True\n",
       "Ohio          False\n",
       "Oregon        False\n",
       "Texas         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform operations between multiple `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California         NaN\n",
      "Ohio           70000.0\n",
      "Oregon         32000.0\n",
      "Texas         142000.0\n",
      "Utah               NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000}\n",
    "states = ['California', 'Ohio', 'Oregon', 'Texas']\n",
    "\n",
    "series_1 = pd.Series(sdata)\n",
    "series_2 = pd.Series(sdata, index=states)\n",
    "\n",
    "print(series_1+series_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we can assign names to the `Series` and its index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State\n",
      "Ohio      35000\n",
      "Texas     71000\n",
      "Oregon    16000\n",
      "Utah       5000\n",
      "Name: Population, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "series_1.name = \"Population\"\n",
    "series_1.index.name = \"State\"\n",
    "print(series_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Series` index can be altered in place by assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4\n",
      "1    7\n",
      "2   -5\n",
      "3    3\n",
      "dtype: int64\n",
      "Bob      4\n",
      "Steve    7\n",
      "Jeff    -5\n",
      "Ryan     3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "series = pd.Series([4, 7, -5, 3])\n",
    "print(series)\n",
    "series.index = ['Bob', 'Steve', 'Jeff', 'Ryan']\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 DataFrames\n",
    "\n",
    "The `DataFrame` has both a row and column **index**; it can be thought of as a dict of `Series` (one for all sharing the same index). Compared with other such DataFrame-like structures you may have used before (like R’s data.frame), row-oriented and column-oriented operations in `DataFrame` are treated roughly symmetrically.\n",
    "\n",
    "Under the hood, the data is stored as one or more two-dimensional blocks rather than a list, dictionary, or some other collection of one-dimensional arrays. The exact details of `DataFrame`’s internals are far outside the scope of this course.\n",
    "\n",
    "There are numerous ways to construct a `DataFrame`, though one of the most common is from a dictionary of equal-length lists or **`NumPy`** arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'State': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'], \n",
    "        'Year': [2000, 2001, 2002, 2001, 2002],\n",
    "        'Population': [1.5, 1.7, 3.6, 2.4, 2.9]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `DataFrame` will have its index assigned automatically as with `Series`, and the columns are placed in sorted order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2002</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>2001</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>2002</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    State  Year  Population\n",
       "0    Ohio  2000         1.5\n",
       "1    Ohio  2001         1.7\n",
       "2    Ohio  2002         3.6\n",
       "3  Nevada  2001         2.4\n",
       "4  Nevada  2002         2.9"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you specify a sequence of columns, the `DataFrame’s` columns will be exactly what you pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   State  Population\n",
       "0  2000    Ohio         1.5\n",
       "1  2001    Ohio         1.7\n",
       "2  2002    Ohio         3.6\n",
       "3  2001  Nevada         2.4\n",
       "4  2002  Nevada         2.9"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=['Year', 'State', 'Population'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with `Series`, if you pass a column that isn’t contained in data, it will appear with `NaN` values in the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'State', 'Population', 'Debt'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "      <th>Debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>2001</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>five</th>\n",
       "      <td>2002</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year   State  Population Debt\n",
       "one    2000    Ohio         1.5  NaN\n",
       "two    2001    Ohio         1.7  NaN\n",
       "three  2002    Ohio         3.6  NaN\n",
       "four   2001  Nevada         2.4  NaN\n",
       "five   2002  Nevada         2.9  NaN"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = pd.DataFrame(data, columns=['Year', 'State', 'Population', 'Debt'],\n",
    "                         index=['one', 'two', 'three', 'four', 'five'])\n",
    "print(df_2.columns)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A column in a `DataFrame` can be retrieved as a `Series` either by dictionary-like notation or by attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'State', 'Population', 'Debt'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "      <th>Debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>2001</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>five</th>\n",
       "      <td>2002</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year   State  Population Debt\n",
       "one    2000    Ohio         1.5  NaN\n",
       "two    2001    Ohio         1.7  NaN\n",
       "three  2002    Ohio         3.6  NaN\n",
       "four   2001  Nevada         2.4  NaN\n",
       "five   2002  Nevada         2.9  NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = pd.DataFrame(data, columns=['Year', 'State', 'Population', 'Debt'],\n",
    "                         index=['one', 'two', 'three', 'four', 'five'])\n",
    "print(df_2.columns)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the returned `Series` have the same index as the `DataFrame`, and their name attribute has been appropriately set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one      2000\n",
       "two      2001\n",
       "three    2002\n",
       "four     2001\n",
       "five     2002\n",
       "Name: Year, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows can also be retrieved by position or name by a couple of methods, such as the `.loc` indexing field (much more on this later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year          2002\n",
       "State         Ohio\n",
       "Population     3.6\n",
       "Debt           NaN\n",
       "Name: three, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.loc['three']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns can be modified by assignment. \n",
    "\n",
    "For example, the empty `Debt` column could be assigned a scalar value or an array of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "      <th>Debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.5</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.7</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>3.6</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>2001</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.4</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>five</th>\n",
       "      <td>2002</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.9</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year   State  Population  Debt\n",
       "one    2000    Ohio         1.5  16.5\n",
       "two    2001    Ohio         1.7  16.5\n",
       "three  2002    Ohio         3.6  16.5\n",
       "four   2001  Nevada         2.4  16.5\n",
       "five   2002  Nevada         2.9  16.5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2['Debt'] = 16.5\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "      <th>Debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>2001</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>five</th>\n",
       "      <td>2002</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year   State  Population  Debt\n",
       "one    2000    Ohio         1.5   0.0\n",
       "two    2001    Ohio         1.7   1.0\n",
       "three  2002    Ohio         3.6   2.0\n",
       "four   2001  Nevada         2.4   3.0\n",
       "five   2002  Nevada         2.9   4.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2['Debt'] = np.arange(5.)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When assigning lists or arrays to a column, the value’s length must match the length of the `DataFrame`. \n",
    "\n",
    "If you assign a `Series`, it will be instead conformed exactly to the `DataFrame’s` index, inserting missing values in any holes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "      <th>Debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>2001</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>five</th>\n",
       "      <td>2002</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.9</td>\n",
       "      <td>-1.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year   State  Population  Debt\n",
       "one    2000    Ohio         1.5   NaN\n",
       "two    2001    Ohio         1.7  -1.2\n",
       "three  2002    Ohio         3.6   NaN\n",
       "four   2001  Nevada         2.4  -1.5\n",
       "five   2002  Nevada         2.9  -1.7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = pd.Series([-1.2, -1.5, -1.7], index=['two', 'four', 'five'])\n",
    "df_2['Debt'] = val\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning a column that doesn’t exist will create a new column. The `del` keyword will delete columns as with a dictinaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "      <th>Debt</th>\n",
       "      <th>Eastern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>2001</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>five</th>\n",
       "      <td>2002</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.9</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year   State  Population  Debt  Eastern\n",
       "one    2000    Ohio         1.5   NaN     True\n",
       "two    2001    Ohio         1.7  -1.2     True\n",
       "three  2002    Ohio         3.6   NaN     True\n",
       "four   2001  Nevada         2.4  -1.5    False\n",
       "five   2002  Nevada         2.9  -1.7    False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2['Eastern'] = df_2.State == 'Ohio'\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'State', 'Population', 'Debt'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "      <th>Debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>2001</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>five</th>\n",
       "      <td>2002</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.9</td>\n",
       "      <td>-1.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year   State  Population  Debt\n",
       "one    2000    Ohio         1.5   NaN\n",
       "two    2001    Ohio         1.7  -1.2\n",
       "three  2002    Ohio         3.6   NaN\n",
       "four   2001  Nevada         2.4  -1.5\n",
       "five   2002  Nevada         2.9  -1.7"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2['Eastern'] = df_2.State == 'Ohio'\n",
    "del df_2['Eastern']\n",
    "print(df_2.columns)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>WARNING: </b> DataFrames and Views\n",
    "\n",
    "The column returned when indexing a DataFrame is a view on the underlying data, not a copy. Thus, any in-place modifications to the Series will be reflected in the DataFrame. The column can be explicitly copied using the .copy() method.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common form of data is a nested dictionary of dictionaries format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nevada': {2001: 2.4, 2002: 2.9}, 'Ohio': {2000: 1.5, 2001: 1.7, 2002: 3.6}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop = {'Nevada': {2001: 2.4, 2002: 2.9},\n",
    "         'Ohio': {2000: 1.5, 2001: 1.7, 2002: 3.6}}\n",
    "pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If passed to `DataFrame`, it will interpret the outer dictionary keys as the columns and the inner keys as the row indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nevada</th>\n",
       "      <th>Ohio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2.4</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Nevada  Ohio\n",
       "2001     2.4   1.7\n",
       "2002     2.9   3.6\n",
       "2000     NaN   1.5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3 = pd.DataFrame(pop)\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And similarilty to **`NumPy`** you can always transpose the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>2.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>1.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        2001  2002  2000\n",
       "Nevada   2.4   2.9   NaN\n",
       "Ohio     1.7   3.6   1.5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keys in the inner dictionaries are unioned and sorted to form the index in the result. This isn’t true if an explicit index is specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nevada</th>\n",
       "      <th>Ohio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2.4</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Nevada  Ohio\n",
       "2002     2.9   3.6\n",
       "2001     2.4   1.7\n",
       "2003     NaN   NaN"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pop, index=[2002, 2001, 2003])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries of `Series` are treated much in the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ohio</th>\n",
       "      <th>Nevada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>1.7</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>3.6</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ohio  Nevada\n",
       "2001   1.7     2.4\n",
       "2002   3.6     2.9"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata = {'Ohio': df_3['Ohio'][:-1],'Nevada': df_3['Nevada'][:2]}\n",
    "pd.DataFrame(pdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a `DataFrame` index and columns have their name attributes set, these will also be displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>State</th>\n",
       "      <th>Nevada</th>\n",
       "      <th>Ohio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2.4</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "State  Nevada  Ohio\n",
       "Year               \n",
       "2001      2.4   1.7\n",
       "2002      2.9   3.6\n",
       "2000      NaN   1.5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.index.name = 'Year'; df_3.columns.name = 'State'\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like `Series`, the `.values` attribute returns the data contained in the `DataFrame` as a 2D `ndarray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.4, 1.7],\n",
       "       [2.9, 3.6],\n",
       "       [nan, 1.5]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the `DataFrame` columns are different `dtypes`, the `dtype` of the values array will be chosen to accomodate all of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.4, 1.7],\n",
       "       [2.9, 3.6],\n",
       "       [nan, 1.5]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible data inputs to `DataFrame` constructor\n",
    "\n",
    "\n",
    "|**Type**   |  **Notes**  |\n",
    "|:---| :---|\n",
    "| 2D `ndarray` |  A matrix of data, passing optional row and column labels|\n",
    "| Dictionary of arrays, lists, or tuples | Each sequence becomes a column in the `DataFrame`. All sequences must be the same length. |\n",
    "| **`NumPy`** structured/record array  | Treated as the “dict of arrays” case |\n",
    "| DDictionary of `Series` | Each value becomes a column. Indexes from each Series are unioned together to form the result’s row index if no explicit index is passed. |\n",
    "| Dictionary of dictionaries |Each inner dict becomes a column. Keys are unioned to form the row index as in the “dict of Series” case.|\n",
    "| List of dictionaries or `Series` | Each item becomes a row in the `DataFrame`. Union of dictionary keys or `Series` indexes become the `DataFrame` column labels |\n",
    "| List of lists or tuples | Treated as the “2D `ndarray`” case |\n",
    "| Another `DataFrame` | The `DataFrame` indexes are used unless different ones are passed |\n",
    "| `NumPy MaskedArray` | Like the “2D `ndarray`” case except masked values become NA/missing in the `DataFrame` result |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Index Objects \n",
    "\n",
    "`Index objects` in **`Pandas`** are responsible for holding the axis labels and other metadata (like the axis name or names). \n",
    "\n",
    "Any array or other sequence of labels used when constructing a `Series` or `DataFrame` is internally converted to an `Index`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "dtype: int64\n",
      "Index(['a', 'b', 'c'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(range(3), index=['a', 'b', 'c'])\n",
    "print(s)\n",
    "index = s.index\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['b', 'c'], dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Index` objects are immutable and thus can’t be modified by the user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Index does not support mutable operations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lyakh\\OneDrive - University College London\\Digital Finance\\Digital_Finance_WORKSHOPS\\workshop_2\\Workshop 2.ipynb Cell 107\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lyakh/OneDrive%20-%20University%20College%20London/Digital%20Finance/Digital_Finance_WORKSHOPS/workshop_2/Workshop%202.ipynb#Y211sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m index[\u001b[39m1\u001b[39;49m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39md\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\lyakh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5347\u001b[0m, in \u001b[0;36mIndex.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   5345\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   5346\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__setitem__\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 5347\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIndex does not support mutable operations\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Index does not support mutable operations"
     ]
    }
   ],
   "source": [
    "index[1] = 'd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immutability is important so that `Index` objects can be safely shared among data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.Index(np.arange(3))\n",
    "s_2 = pd.Series([1.5, -2.5, 0], index=index)\n",
    "s_2.index is index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>TIP: </b> Index objects\n",
    "\n",
    "You will not need to know much about Index objects, but they’re nonetheless an important part of pandas’s data model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In addition to being array-like, an `Index` also functions as a fixed-size set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_3)\n",
    "print('Ohio' in df_3.index)\n",
    "print(2003 in df_3.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `Index` has a number of methods and properties for set logic and answering other common questions about the data it contains.\n",
    "\n",
    "`Index` methods and properties\n",
    "\n",
    "\n",
    "|**Method**   |  **Description**  |\n",
    "|:---| :---|\n",
    "| `.append()` | Concatenate with additional `Index` objects, producing a new `Index` |\n",
    "| `.diff()` |  Compute set difference as an `Index` |\n",
    "| `.intersection()` | Compute set intersection |\n",
    "| `.union()` | Compute set union |\n",
    "| `.isin()` | Compute boolean array indicating whether each value is contained in the passed collection |\n",
    "| `.delete()` | Compute new `Index` with element at index `i` deleted |\n",
    "| `.drop()` | Compute new `Index` by deleting passed values |\n",
    "| `.insert()* | Compute new `Index` by inserting element at index `i` |\n",
    "| `.is_monotonic()` | Returns `True` if each element is greater than or equal to the previous element |\n",
    "| `.is_unique()` | Returns `True` if the `Index` has no duplicate values |\n",
    "| `.unique()` | Compute the array of unique values in the `Index` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Index Objects: Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (2):</b>\n",
    "\n",
    "Use below data about the number of graduate students at UCL to create a data frame, called **df_grad**. Once the data frame is created please check if there are any missing values.\n",
    "<p>\n",
    "grad = {'2015-16': {'Male': 7980, 'Female': 12490},\n",
    "        '2016-17': {'Male': 8090, 'Female': 13075},\n",
    "        '2017-18': {'Male': 8410, 'Female': None}}\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (3):</b>\n",
    "\n",
    "You must have realized that there is a missing value - please update that value with 13895.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>TIP: </b> SettingWithCopyWarning\n",
    "\n",
    "The SettingWithCopyWarning was created to flag \"chained assignment\" operations. Please refer to this [link](https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas) for detail explanation and see how you can aviod it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (4):</b>\n",
    "\n",
    "Please transpose the data frame and save it as **df_grad_new**.\n",
    "\n",
    "Once that is done please add a new column called **Total** and populate it with the sum of values from columns **Female** and **Male**.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (5):</b>\n",
    "\n",
    "Write the code that shows just one column of the data frame - **Total**.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (6):</b>\n",
    "\n",
    "Write the code that checks if the string **2014-15** is in the index of **df_grad_new** data frame.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Essential Functionality\n",
    "\n",
    "Now lets look at the fundamental mechanics of interacting with the data contained in a `Series` or `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Reindexing\n",
    "\n",
    "A critical method on `Pandas` objects is `.reindex()`, which means to create a new object with the data conformed to a new index. Consider a simple example from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([4.5, 7.2, -5.3, 3.6], index=['d', 'b', 'a', 'c'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `.reindex()` on this `Series` rearranges the data according to the new index, introducing missing values if any index values were not already present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_2 = s.reindex(['a', 'b', 'c', 'd', 'e'])\n",
    "s_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.reindex(['a', 'b', 'c', 'd', 'e'], fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ordered data like time series, it may be desirable to do some interpolation or filling of values when reindexing. The method option allows us to do this, using a method such as `.ffill()` which forward fills the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_3 = pd.Series(['blue', 'purple', 'yellow'], index=[0, 2, 4])\n",
    "s_3.reindex(range(6), method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this time, interpolation more sophisticated than forward- and backfilling would need to be applied after the fact.\n",
    "\n",
    "`.reindex()`  **method (interpolation) options**\n",
    "\n",
    "\n",
    "|**Argument**   |  **Description**  |\n",
    "|:---| :---|\n",
    "| `ffill` or `pad` | Fill (or carry) values forward |\n",
    "| `bfill` or `backfill` | Fill (or carry) values backward |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `DataFrame`, `.reindex()` can alter either the (row) index, columns, or both. \n",
    "\n",
    "When passed just a sequence, the rows are reindexed in the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(9).reshape((3, 3)), index=['a', 'c', 'd'], columns=['Ohio', 'Texas', 'California'])\n",
    "print(df)\n",
    "df_2 = df.reindex(['a','b','c','d'])\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns can be reindexed using the `columns` keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['Texas', 'Utah', 'California']\n",
    "df.reindex(columns=states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both can be reindexed in one shot, though interpolation will only apply row-wise (axis 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reindex(index=['a','b','c','d'],columns=states).ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.reindex()`  **method arguments**\n",
    "\n",
    "\n",
    "|**Argument**   |  **Description**  |\n",
    "|:---| :---|\n",
    "| `index` | New sequence to use as index. Can be `Index` instance or any other sequence-like **`Python`** data structure. An `Index` will be used exactly as is without any copying |\n",
    "| `method` | Interpolation (fill) method |\n",
    "| `fill_value` | Substitute value to use when introducing missing data by reindexing |\n",
    "| `limit` | When forward- or backfilling, maximum size gap to fill |\n",
    "| `level` | Match simple `Index` on level of `MultiIndex`, otherwise select subset of |\n",
    "| `copy` | Do not copy underlying data if new index is equivalent to old index. `True` by default (i.e. always copy data). |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Dropping Entries from an Axis\n",
    "\n",
    "Dropping one or more entries from an axis is easy if you have an index array or list without those entries. \n",
    "\n",
    "As that can require a bit of munging and set logic, the drop method will return a new object with the indicated value or values deleted from an axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "s = pd.Series(np.arange(5.), index=['a', 'b', 'c', 'd', 'e'])\n",
    "s_2 = s.drop('c')\n",
    "print(s_2)\n",
    "s.drop(['d','c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `DataFrame`, index values can be deleted from either axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(16).reshape((4, 4)),\n",
    "                 index=['Ohio', 'Colorado', 'Utah', 'New York'],\n",
    "                 columns=['one', 'two', 'three', 'four'])\n",
    "\n",
    "print(df.drop(['Colorado', 'Ohio']))\n",
    "print(df.drop('two', axis=1))\n",
    "df.drop(['two', 'four'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Indexing, Selection, and Filtering\n",
    "\n",
    "`Series` indexing (`obj[...]`) works analogously to **`NumPy`** array indexing, except you can use the `Series` index values instead of only integers. Here are some examples of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.arange(4.), index=['a', 'b', 'c', 'd'])\n",
    "print(s['b'])\n",
    "print(s[1])\n",
    "print(s[2:4])\n",
    "s[['b','a','d']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing with labels behaves differently than normal **`Python`** slicing in that the endpoint is **inclusive**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['b':'c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting using these methods works just as you would expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['b':'c'] = 5\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we’ve seen above, indexing into a `DataFrame` is for retrieving one or more columns either with a single value or sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(16).reshape((4, 4)),\n",
    "                 index=['Ohio', 'Colorado', 'Utah', 'New York'],\n",
    "                 columns=['one', 'two', 'three', 'four'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['two'])\n",
    "df[['three','one']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing like this has a few special cases. First selecting rows by slicing or a boolean array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[:2])\n",
    "df[df['three'] > 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>WARNING: </b> Pandas indexing\n",
    "\n",
    "Pandas indexing might seem inconsistent to some readers, but this syntax practicality makes things a bit easier.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another use case is in indexing with a boolean `DataFrame`, such as one produced by a scalar comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df < 5] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are many ways to select and rearrange the data contained in a **`Pandas`** object. \n",
    "\n",
    "For `DataFrame`, there is a short summary of many of them below. You have a number of additional options when working with hierarchical indexes as we’ll later see.\n",
    "\n",
    "**Indexing options with DataFrame**\n",
    "\n",
    "\n",
    "|**Type**   |  **Notes**  |\n",
    "|:---| :---|\n",
    "| `obj[val]` | Select single column or sequence of columns from the `DataFrame`. Special case conveniences: boolean array (filter rows), slice (slice rows), or boolean `DataFrame` (set values based on some criterion). |\n",
    "| `obj.ix[val]` | Selects single row of subset of rows from the `DataFrame`. |\n",
    "| `obj.ix[:,va;]` | Selects single column of subset of columns. |\n",
    "| `obj.ix[val1, val2]` | Select both rows and columns. |\n",
    "| `.reindex()` | Conform one or more axes to new indexes. |\n",
    "| `.xs()` | Select single row or column as a Series by label. |\n",
    "| `.icol()`, `.irow()` | Select single column or row, respectively, as a `Series` by integer location. |\n",
    "| `.get_value()`, `.set_value()` | Select single value by row and column label. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 Arithmetic and Data Alignment\n",
    "\n",
    "One of the most important `Pandas` features is the behavior of arithmetic between objects with different indexes. When adding together objects, if any index pairs are not the same, the respective index in the result will be the union of the index pairs. Let’s look at a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_1 = pd.Series([7.3, -2.5, 3.4, 1.5], index=['a', 'c', 'd', 'e'])\n",
    "s_2 = pd.Series([-2.1, 3.6, -1.5, 4, 3.1], index=['a', 'c', 'e', 'f', 'g'])\n",
    "print(s_1)\n",
    "print(s_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding these together yields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_1 + s_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The internal data alignment introduces `NA` values in the indices that don’t overlap. Missing values propagate in arithmetic computations.\n",
    "\n",
    "In the case of `DataFrame`, alignment is performed on both the rows and the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(np.arange(9.).reshape((3, 3)), columns=list('bcd'), index=['Ohio', 'Texas', 'Colorado'])\n",
    "df_2 = pd.DataFrame(np.arange(12.).reshape((4, 3)), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'])\n",
    "print(df_1)\n",
    "print(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding these together returns a `DataFrame` whose index and columns are the unions of the ones in each `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 + df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic Methods with Fill Values\n",
    "\n",
    "In arithmetic operations between differently-indexed objects, you might want to fill with a special value, like 0, when an axis label is found in one object but not the other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(np.arange(12.).reshape((3, 4)), columns=list('abcd'))\n",
    "df_2 = pd.DataFrame(np.arange(20.).reshape((4, 5)), columns=list('abcde'))\n",
    "print(df_1)\n",
    "print(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding these together results in NA values (`NaN`) in the locations that don’t overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 + df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the add method on `df_1`, we can pass `df_2` and an argument to `fill_value`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.add(df_2, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatedly, when reindexing a `Series` or `DataFrame`, you can also specify a different fill value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.reindex(columns=df_2.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flexible arithmetic methods**\n",
    "\n",
    "|**Method**   |  **Description**  |\n",
    "|:---| :---|\n",
    "| `.add()` | Method for addition (+) |\n",
    "| `.sub()` | Method for subtraction (-) |\n",
    "| `.div()` | Method for division (/) |\n",
    "| `.mul()` | Method for multiplication (*) |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations Between DataFrame and Series\n",
    "\n",
    "As with **`NumPy`** arrays, arithmetic between `DataFrame` and `Series` is well-defined. \n",
    "\n",
    "First, as a motivating example, consider the difference between a 2D array and one of its rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(12.).reshape((3, 4))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr - arr[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is referred to as **broadcasting** but we won't go into detail her. \n",
    "\n",
    "Operations between a `DataFrame` and a `Series` are similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(12.).reshape((4, 3)), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'])\n",
    "series = df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, arithmetic between `DataFrame` and `Series` matches the index of the `Series` on the `DataFrame` columns, broadcasting down the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df - series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an index value is not found in either the `DataFrame` columns or the `Series` index, the objects will be reindexed to form the union:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_2 = pd.Series(range(3), index=['b', 'e', 'f'])\n",
    "df + series_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to instead broadcast over the columns, matching on the rows, you have to use one of the arithmetic methods. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_3 = df['d']\n",
    "print(df)\n",
    "series_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The axis number that you pass is the axis to match on. In this case we mean to match on the `DataFrame` row index and broadcast across.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sub(series_3, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 Function Application and Mapping\n",
    "\n",
    "**`NumPy`** ufuncs (element-wise array methods) work fine with `Pandas` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(4, 3), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'])\n",
    "print(df)\n",
    "np.abs(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another frequent operation is applying a function on 1D arrays to each column or row. `DataFrame` apply method does exactly this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't worry about Lambda functions, we will return to this in following weeks\n",
    "f = lambda x: x.max() - x.min()\n",
    "print(df.apply(f))\n",
    "df.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "TIP: Dataframe methods\n",
    "\n",
    "Many of the most common array statistics (like sum and mean) are DataFrame methods,\n",
    "so using the .apply() method is not necessary. Over time, and with practise, you will memorize those than you use most frequently.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function passed to apply need not return a scalar value, it can also return a `Series`\n",
    "with multiple values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return pd.Series([x.min(), x.max()], index=['min', 'max'])\n",
    "\n",
    "df.apply(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Element-wise Python functions can be used, too. Suppose you wanted to compute a formatted string from each floating point value in `df`. You can do this with `.applymap()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format = lambda x: '%.2f' % x\n",
    "df.applymap(format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for the name `.applymap()` is that `Series` has a map method for applying an element-wise function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['e'].map(format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 Sorting and Ranking\n",
    "\n",
    "Sorting a data set by some criterion is another important built-in operation. To sort lexicographically by row or column index, use the `.sort_index()` method, which returns a new, sorted object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(range(4), index=['d', 'a', 'b', 'c'])\n",
    "s.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a `DataFrame`, you can sort by index on either axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(8).reshape((2, 4)), index=['three', 'one'], columns=['d', 'a', 'b', 'c'])\n",
    "print(df.sort_index())\n",
    "df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is *sorted* in ascending order by default, but can be sorted in descending order, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sort a `Series` by its values, use its `.sort_values()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([4, 7, -3, 2])\n",
    "s.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Any missing values are sorted to the end of the `Series` by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([4,np.nan,7, np.nan, -3, 2])\n",
    "s.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On `DataFrame`, you may want to sort by the values in one or more columns. To do so, pass one or more column names to the by option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'b': [4, 7, -3, 2], 'a': [0, 1, 0, 1]})\n",
    "print(df)\n",
    "df.sort_values(by='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sort by multiple columns, pass a list of names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['a', 'b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ranking** is closely related to sorting, assigning ranks from one through the number of valid data points in an array. It is similar to the indirect sort indices produced by `numpy.argsort`, except that ties are broken according to a rule. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.rank()` methods for `Series` and `DataFrame` are the place to look; by default `.rank()` breaks ties by assigning each group the mean rank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([7, -5, 7, 4, 2, 0, 4])\n",
    "s.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranks can also be assigned according to the order they’re observed in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.rank(method='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, you can rank in descending order, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.rank(ascending=False, method='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` can compute ranks over the rows or the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'b': [4.3, 7, -3, 2], 'a': [0, 1, 0, 1], 'c': [-2, 5, 8, -2.5]})\n",
    "print(df)\n",
    "df.rank(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tie-breaking methods with** `.rank()`\n",
    "\n",
    "\n",
    "\n",
    "|**Method**   |  **Description**  |\n",
    "|:---| :---|\n",
    "| `average` | Default: assign the average rank to each entry in the equal group. |\n",
    "| `max` | Use the maximum rank for the whole group. |\n",
    "| `min` | Use the minimum rank for the whole group. |\n",
    "| `first` | Assign ranks in the order the values appear in the data. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.4 Axis Indexes with Duplicate Values\n",
    "\n",
    "Up until now all of the examples we’ve seen have had unique axis labels (index values). \n",
    "\n",
    "While many **`Pandas`** functions (like `.reindex()`) require that the labels be unique, it’s not mandatory. \n",
    "\n",
    "Let’s consider a small Series with duplicate indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(range(5), index=['a', 'a', 'b', 'b', 'c'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index’s `.is_unique()` attribute can tell you whether its values are unique or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data selection is one of the main things that behaves differently with duplicates. \n",
    "\n",
    "Indexing a value with multiple entries returns a `Series` while single entries return a scalar value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s['a'])\n",
    "s['c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same logic extends to indexing rows in a `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(4, 3), index=['a', 'a', 'b', 'b'])\n",
    "print(df)\n",
    "df.loc['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.5 Indexing, Selection, and Filtering: Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (7): </b> \n",
    "\n",
    "Write a code that creates two series one with numbers from 0 to 7 and the other one with numbers from 7 to 0. \n",
    "\n",
    "Use the following letters for indexing **index=['a','b', 'c', 'd', 'x', 'f', 'g', 'h']**.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (8): </b>\n",
    "\n",
    "Create a dataframe with the index from excersise 6 and with columns obj1 and obj2 that contain values from the series.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (9): </b> \n",
    "\n",
    "Replace x in the index with e.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (10): </b>\n",
    "\n",
    "Sort the dataframe by index from h to a.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (11): </b>\n",
    "\n",
    "<p> Write a code that shows the the following part of the dataframe.</p>\n",
    "  <p><code>d &nbsp;   4</p>\n",
    "<p>e  &nbsp;  3</code></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Computing Descriptive Statistics\n",
    "\n",
    "**`Pandas`** objects are equipped with a set of common mathematical and statistical methods. Most of these fall into the category of reductions or summary statistics, methods that extract a single value (like the `.sum()` or `.mean()`) from a `Series` or a `Series` of values from the rows or columns of a `DataFrame`.\n",
    "\n",
    "Compared with the equivalent methods of vanilla **`NumPy`** arrays, they are all built from the ground up to exclude missing data. Consider a small DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1.4, np.nan], [7.1, -4.5], [np.nan, np.nan], [0.75, -1.3]], index=['a', 'b', 'c', 'd'], columns=['one', 'two'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `.sum()` method returns a `Series` containing column sums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing `axis=1` sums over the rows instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NA values are excluded unless the entire slice (row or column in this case) is NA. This can be disabled using the `skipna` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis=1, skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arguments for reduction methods**\n",
    "\n",
    "|**Argument**   |  **Description**  |\n",
    "|:---| :---|\n",
    "| `axis` | Axis to reduce over. 0 for `DataFrame`’s rows and 1 for columns. |\n",
    "| `skipna` | Exclude missing values, `True` by default. |\n",
    "| `level` | Reduce grouped by level if the axis is hierarchically-indexed (`MultiIndex`).|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some methods, like `.idxmin()` and `.idxmax()`, return indirect statistics like the index value where the minimum or maximum values are attained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other methods are **accumulations**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another type of method is neither a reduction nor an accumulation. `.describe()` is one such example, producing multiple summary statistics in one shot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On non-numeric data, `.describe()` produces alternate summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(['a', 'a', 'b', 'c'] * 4)\n",
    "s.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descriptive and summary statistics**\n",
    "\n",
    "\n",
    "\n",
    "|**Method**   |  **Description**  |\n",
    "|:---| :---|\n",
    "| **`count`** | Number of non-NA values |\n",
    "| **`describe`** | Compute set of summary statistics for **`Series`** or each **`DataFrame`** column |\n",
    "| **`min`**, **`max`** | Compute minimum and maximum values |\n",
    "| **`argmin`**, **`argmax`** | Compute index locations (integers) at which minimum or maximum value obtained, respectively |\n",
    "| **`idxmin`**, **`idxmin`** | Compute index values at which minimum or maximum value obtained, respectively |\n",
    "| **`quartile`** | Compute sample quantile ranging from 0 to 1 |\n",
    "| **`sum`** | Sum of values |\n",
    "| **`mean`** | Mean of values |\n",
    "| **`median`** | Arithmetic median (50% quantile) of values |\n",
    "| **`mad`** | Mean absolute deviation from mean value |\n",
    "| **`var`** | Sample variance of values |\n",
    "| **`std`** | Sample standard deviation of values |\n",
    "| **`skew`** | Sample skewness (3rd moment) of values |\n",
    "| **`kurt`** | Sample kurtosis (4th moment) of values |\n",
    "| **`cumsum`** | Cumulative sum of values |\n",
    "| **`cummin`**, **`cummax`** | Cumulative minimum or maximum of values, respectively |\n",
    "| **`cumprod`** | Cumulative product of values |\n",
    "| **`diff`** | Compute 1st arithmetic difference (useful for time series) |\n",
    "| **`pct_change`** | Compute percent changes |     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1 Correlation and Covariance\n",
    "\n",
    "Some summary statistics, like correlation and covariance, are computed from pairs of arguments. \n",
    "\n",
    "Let’s consider some `DataFrames` of stock prices and volumes obtained from **`Yahoo! Finance`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime\n",
    "\n",
    "start = datetime.datetime(2000, 1, 1)\n",
    "end = datetime.datetime(2010, 1, 1)\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "for ticker in ['AAPL', 'IBM', 'MSFT', 'GOOGL']: \n",
    "    try:\n",
    "        all_data[ticker] = yf.download(ticker, start, end)\n",
    "    except:\n",
    "        print(\"Can't find \", ticker)\n",
    "\n",
    "price_df = pd.DataFrame({tic: data['Adj Close'] for tic, data in all_data.items()})\n",
    "volume_df = pd.DataFrame({tic: data['Volume'] for tic, data in all_data.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the percentage changes of the prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = price_df.pct_change()\n",
    "returns.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.corr()` method of `Series` computes the correlation of the overlapping, non-NA, aligned-by-index values in two `Series`. Relatedly, `.cov()` computes the covariance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(returns.AAPL.corr(returns.IBM))\n",
    "print(returns.AAPL.cov(returns.IBM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.corr()` and `.cov()` methods, on the other hand, return a full correlation or covariance matrix as a `DataFrame`, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `.corrwith()` method, you can compute pairwise correlations between a `DataFrame` columns or rows with another `Series` or `DataFrame`. Passing a `Series` returns a `Series` with the correlation value computed for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.corrwith(returns.IBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing a `DataFrame` computes the correlations of matching column names. Here we compute correlations of percent changes with volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.corrwith(volume_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2 Unique Values, Value Counts, and Membership\n",
    "\n",
    "Another class of related methods extracts information about the values contained in a one-dimensional `Series`. To illustrate these, consider this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(['c', 'a', 'd', 'a', 'a', 'b', 'b', 'c', 'c'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function is `.unique()`, which gives you an array of the unique values in a `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = s.unique()\n",
    "uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unique values are not necessarily returned in sorted order, but could be sorted after the fact if needed (`uniques.sort()`). Relatedly, `.value_counts()` computes a `Series` containing value frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Series` is sorted by value in descending order as a convenience. `.value_counts()` is also available as a top-level `Pandas` method that can be used with any array or sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(s.values, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, `.isin()` is responsible for vectorized set membership and can be very useful in filtering a data set down to a subset of values in a `Series` or column in a `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = s.isin(['b', 'c'])\n",
    "print(mask)\n",
    "s[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unique, value counts, and binning methods**\n",
    "\n",
    "\n",
    "|**Method**   |  **Description**  |\n",
    "|:---| :---|\n",
    "| `.isin()` | Compute boolean array indicating whether each `Series` value is contained in the passed sequence of values. |\n",
    "| `.unique()` | Compute array of unique values in a `Series`, returned in the order observed. |\n",
    "| `.value_counts()` | Return a `Series` containing unique values as its index and frequencies as its values, ordered count in descending order. |\n",
    "\n",
    "In some cases, you may want to compute a histogram on multiple related columns in a `DataFrame`. Here’s an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Qu1': [1, 3, 4, 3, 4], \n",
    "                  'Qu2': [2, 3, 1, 2, 3],\n",
    "                  'Qu3': [1, 5, 2, 4, 4]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing `pandas.value_counts()` to this `DataFrame` `.apply()` method gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.apply(pd.value_counts).fillna(0)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Handling Missing Data\n",
    "\n",
    "Missing data is common in most data analysis applications. `Pandas` was designed to make working with missing data as painless as possible. \n",
    "\n",
    "For example, all of the descriptive statistics on `Pandas` objects exclude missing data as we’ve seen earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pandas` uses the floating point value `NaN` (*Not a Number*) to represent missing data in both floating as well as in non-floating point arrays. It is just used as a *sentinel* that can be easily detected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_data = pd.Series(['aardvark', 'artichoke', np.nan, 'avocado'])\n",
    "print(string_data)\n",
    "string_data.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in **`Python`** `None` value is also treated as NA in object arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_data[0] = None\n",
    "string_data.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NA handling methods**\n",
    "\n",
    "\n",
    "|**Method**   |  **Description**  |\n",
    "|:---| :---|\n",
    "| `.dropna()` | Filter axis labels based on whether values for each label have missing data, with varying thresholds for how much missing data to tolerate. |\n",
    "| `.fillna()` | Fill in missing data with some value or using an interpolation method such as `ffill` or `bfill` |\n",
    "| `.isnull()` | Return like-type object containing boolean values indicating which values are missing / NA. |\n",
    "| `.notnull()` | Negation of `.isnull()` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.1 Filtering Out Missing Data\n",
    "\n",
    "There are a number of options for filtering out missing data. While doing it by hand is always an option, `.dropna()` can be very helpful. \n",
    "\n",
    "On a `Series`, it returns the `Series` with only the non-null data and index values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan as NA\n",
    "\n",
    "data = pd.Series([1, NA, 3.5, NA, 7])\n",
    "print(data)\n",
    "data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could have computed this yourself by boolean indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, with `DataFrame` objects, these are a bit more complex. You may want to drop rows or columns which are all NA or just those containing any NAs. `.dropna()` by default drops any row containing a missing value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([[1., 6.5, 3.], [1., NA, NA], [NA, NA, NA], [NA, 6.5, 3.]])\n",
    "cleaned = data.dropna()\n",
    "print(data)\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing `how='all'` will only drop rows that are all NA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping columns in the same way is only a matter of passing `axis=1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[4] = NA\n",
    "print(data)\n",
    "data.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A related way to filter out `DataFrame` rows tends to concern time series data. Suppose you want to keep only rows containing a certain number of observations. You can indicate this with the thresh argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(7, 3))\n",
    "df.loc[:4,1] = NA\n",
    "df.loc[:2,2] = NA\n",
    "print(df)\n",
    "df.dropna(thresh=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.2 Filling In Missing Data\n",
    "\n",
    "Rather than filtering out missing data (and potentially discarding other data along with it), you may want to fill in the “holes” in any number of ways. \n",
    "\n",
    "For most purposes, the `.fillna()` method is the workhorse function to use. Calling `.fillna()` with a constant replaces missing values with that value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `.fillna()` with a dict you can use a different fill value for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna({1: 0.5, 2: -1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.fillna()` returns a new object, but you can modify the existing object in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always returns a reference to the filled object\n",
    "_ = df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same interpolation methods available for reindexing can be used with `.fillna()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(6, 3))\n",
    "df.loc[2:, 1] = NA; df.loc[4:, 2] = NA\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method='ffill', limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `.fillna()` you can do lots of other things with a little creativity. \n",
    "\n",
    "For example, you might pass the mean or median value of a `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([1., NA, 3.5, NA, 7])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.fillna()` **method arguments**\n",
    "\n",
    "\n",
    "|**Argument**   |  **Description**  |\n",
    "|:---| :---|\n",
    "| `value` | Scalar value or dict-like object to use to fill missing values |\n",
    "| `method` | Interpolation, by default `ffill` if function called with no other arguments |\n",
    "| `axis` | Axis to fill on, default `axis=0` |\n",
    "| `inplace` | Modify the calling object without producing a copy |\n",
    "| `limit` | For forward and backward filling, maximum number of consecutive periods to fill |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.3 Handling Missing Data: Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Exrecises (12-16)Intro:</b>\n",
    "\n",
    "Create a dataframe called **df** using the below code:\n",
    "\n",
    "\n",
    "data = {'name': ['Jack', np.nan, 'Anna', 'Michael', 'Vanessa', 'Andrew', 'Monica'], \n",
    "         'surname': ['Snow', np.nan, 'Scott', 'Jordna', 'Willis', 'Hughes', 'Dee'],        \n",
    "         'age': [31, np.nan, 23, 26, 21, 28, 24],\n",
    "         'sex': ['m', np.nan, 'f', 'm', 'f', 'm', 'f'], \n",
    "         'quiz1': [71, np.nan, np.nan, 65, 59, 61, 73],\n",
    "         'quiz2': [85, np.nan, np.nan, 76, 68, 65, 80]}\n",
    "\n",
    "<br>\n",
    "\n",
    "df = pd.DataFrame(data, columns = ['name', 'surname', 'age', 'sex', 'quiz1', 'quiz2'])\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (12):</b>\n",
    "\n",
    "Check if there are any missing values in the dataframe.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (13):</b>\n",
    "\n",
    "Write a code to drop rows that have any missing values.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (14):</b>\n",
    "\n",
    "Write a code to drop rows that have all values missing. Then replace the remaining missing values with the mean for the given column.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (15):</b>\n",
    "\n",
    "Write a code to replace the missing values using backward filling method.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (16):</b>\n",
    "\n",
    "Write a code to see which cells do **not** contain missing values.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Custom Data Import\n",
    "\n",
    "The pandas package is also great at dealing with many of the issues you will encounter when importing data, such as:\n",
    "\n",
    " - Comments\n",
    " - Empty rows, columns, and missing values. \n",
    "\n",
    "Note that missing values are also commonly referred to as `NA` or `NaN`.\n",
    "\n",
    "We can easily import files of mixed data types as DataFrames using the pandas functions \n",
    "- `.read_csv()`\n",
    "- `.read_excel()`\n",
    "- `.read_table()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "# Assign the filename: file\n",
    "file = './static/pima-indians-diabetes.csv'\n",
    "\n",
    "# Read the file into a DataFrame: df\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# View the head of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve the corresponding numpy array using the attribute values from the `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a numpy array from the DataFrame: data_array\n",
    "data_array = df.values\n",
    "\n",
    "# Print the datatype of data_array to the shell\n",
    "print(type(data_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of arguments that `pd.read_csv()` takes: \n",
    "\n",
    "- `sep` is the **`Pandas`** version of `delim`\n",
    "- `comment` takes characters that comments occur after in the file, which in this case is '#'. \n",
    "- `na_values` takes a list of strings to recognize as NA/NaN, in this case the string 'Nothing'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assign filename: file\n",
    "file = './static/titanic_corrupt.txt'\n",
    "\n",
    "# Import file: data\n",
    "data = pd.read_csv(file, sep='\\t', comment='#', na_values='Nothing')\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "print(data.head())\n",
    "\n",
    "# Plot 'Age' variable in a histogram\n",
    "pd.DataFrame.hist(data[['Age']])\n",
    "plt.xlabel('Age (years)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Combining and Merging Data Sets\n",
    "\n",
    "Data contained in `Pandas` objects can be combined together in a number of built-in ways:\n",
    "\n",
    "- `pandas.merge` connects rows in `DataFrames` based on one or more keys. This will be familiar to users of **SQL** or other relational databases, as it implements database join operations.\n",
    "- `pandas.concat` concatenates or stacks together objects along an axis.\n",
    "- `combine_first` instance method enables splicing together overlapping data to fill in missing values in one object with values from another.\n",
    "\n",
    "We will use examples of this throughout the rest of the course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.1 Database-Style **`DataFrame`** Merges\n",
    "\n",
    "**Merge** or **join** operations combine data sets by linking rows using one or more **keys**. These operations are central to relational databases. The merge function in **`Pandas`** is the main entry point for using these algorithms on your data. \n",
    "\n",
    "Let’s start with a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': range(7)})\n",
    "df_2 = pd.DataFrame({'key': ['a', 'b', 'd'], 'data2': range(3)})\n",
    "print(df_1)\n",
    "print(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a **many-to-one** merge situation; the data in `df_1` has multiple rows labeled `a` and `b`, whereas `df_2` has only one row for each value in the key column. Calling merge with these objects we obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_1, df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we didn’t specify which column to join on. If not specified, merge uses the overlapping column names as the **keys**. \n",
    "\n",
    "It is good practice to specify explicitly, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_1, df_2, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the column names are different in each object, you can specify them separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.DataFrame({'lkey': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': range(7)})\n",
    "df_4 = pd.DataFrame({'rkey': ['a', 'b', 'd'], 'data2': range(3)})\n",
    "print(df_3)\n",
    "print(df_4)\n",
    "pd.merge(df_3, df_4, left_on='lkey', right_on='rkey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably noticed that the `c` and `d` values and associated data are missing from the result. By default merge does an **inner** join; the keys in the result are the *intersection*. \n",
    "\n",
    "Other possible options are **left**, **right**, and **outer**. \n",
    "\n",
    "The outer join takes the union of the keys, combining the effect of applying both left and right joins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_1, df_2, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Many-to-many** merges have well-defined though not necessarily intuitive behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'b'], 'data1': range(6)})\n",
    "df_2 = pd.DataFrame({'key': ['a', 'b', 'a', 'b', 'd'], 'data2': range(5)})\n",
    "print(df_1)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_1, df_2, on='key', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Many-to-many* joins form the Cartesian product of the rows. Since there were 3 `b` rows in the left `DataFrame` and 2 `b` rows in the right one, there are 6 `b` rows in the result.\n",
    "\n",
    "The join method only affects the distinct key values appearing in the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_1, df_2, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge with multiple keys, pass a list of column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key1': ['foo', 'foo', 'bar'], \n",
    "                  'key2': ['one', 'two', 'one'],\n",
    "                  'lval': [1, 2, 3]})\n",
    "right = pd.DataFrame({'key1': ['foo', 'foo', 'bar', 'bar'], \n",
    "                   'key2': ['one', 'one', 'one', 'two'],\n",
    "                   'rval': [4, 5, 6, 7]})\n",
    "print(left)\n",
    "print(right)\n",
    "pd.merge(left, right, on=['key1', 'key2'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>HINT:</b> Key combinations \n",
    "\n",
    "<p> To determine which key combinations will appear in the result depending on the choice of merge method, think of the multiple keys as forming an array of tuples to be used as a single join key (even though it’s not actually implemented that way).</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "<br>\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>WARNING: </b> \n",
    "\n",
    "When joining columns-on-columns, the indexes on the passed DataFrame objects are discarded.\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A last issue to consider in merge operations is the treatment of overlapping column names. While you can address the overlap manually (see the later section on renaming axis labels), merge has a suffixes option for specifying strings to append to overlapping names in the left and right `DataFrame` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left, right, on='key1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left, right, on='key1', suffixes=('_left', '_right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`pandas.merge`** **function arguments**\n",
    "\n",
    "| **Argumnet** | **Description** |\n",
    "| --- | --- |\n",
    "| `left` | `DataFrame` to be merged on the left side |\n",
    "| `right` | `DataFrame` to be merged on the right side |\n",
    "| `how` | One of `inner`, `outer`, `left` or `right`. `inner` by default |\n",
    "| `on` | Column names to join on. Must be found in both `DataFrame` objects. If not specified and no other join keys given, will use the intersection of the column names in left and right as the join keys |\n",
    "| `left_on` | Columns in left `DataFrame` to use as join keys |\n",
    "| `right_on` | Analogous to `left_on` for left `DataFrame` |\n",
    "| `left_index` | Use row index in `left` as its join key (or keys, if a MultiIndex) |\n",
    "| `right_index` | Analogous to `left_index` |\n",
    "| `sort` | Sort merged data lexicographically by join keys; `True` by default. Disable to get better performance in some cases on large datasets |\n",
    "| `suffixes` | Tuple of string values to append to column names in case of overlap; defaults to (`_x`, `_y`). For example, if 'data' in both `DataFrame` objects, would appear as `data_x` and `data_y` in result |\n",
    "| `copy` | If `False`, avoid copying data into resulting data structure in some exceptional cases. By default always copies |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.2 Merging on `Index`\n",
    "\n",
    "In some cases, the merge key or keys in a `DataFrame` will be found in its index. \n",
    "\n",
    "In this case, you can pass `left_index=True` or `right_index=True` (or both) to indicate that the index should be used as the merge key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_1 = pd.DataFrame({'key': ['a', 'b', 'a', 'a', 'b', 'c'], 'value': range(6)})\n",
    "right_1 = pd.DataFrame({'group_val': [3.5, 7]}, index=['a', 'b'])\n",
    "print(left_1)\n",
    "right_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left_1, right_1, left_on='key', right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the default merge method is to intersect the join keys, you can instead form the union of them with an outer join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left_1, right_1, left_on='key', right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With hierarchically-indexed data, things are a bit more complicated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lefth = pd.DataFrame({'key1': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'], \n",
    "                   'key2': [2000, 2001, 2002, 2001, 2002],\n",
    "                   'data': np.arange(5.)})\n",
    "righth = pd.DataFrame(np.arange(12).reshape((6, 2)), \n",
    "                   index=[['Nevada', 'Nevada', 'Ohio', 'Ohio', 'Ohio', 'Ohio'],\n",
    "                          [2001, 2000, 2000, 2000, 2001, 2002]],\n",
    "                   columns=['event1', 'event2'])\n",
    "print(lefth)\n",
    "righth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, you have to indicate multiple columns to merge on as a list (pay attention to the handling of duplicate index values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(lefth, righth, left_on=['key1', 'key2'], right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(lefth, righth, left_on=['key1', 'key2'], right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the indexes of both sides of the merge is also not an issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_2 = pd.DataFrame([[1., 2.], [3., 4.], [5., 6.]], \n",
    "                  index=['a', 'c', 'e'], columns=['Ohio', 'Nevada'])\n",
    "right_2 = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [13, 14]],\n",
    "                   index=['b', 'c', 'd', 'e'], columns=['Missouri', 'Alabama'])\n",
    "print(left_2)\n",
    "right_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left_2, right_2, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` has a more convenient join instance for merging by index. It can also be used to combine together many `DataFrame` objects having the same or similar indexes but non-overlapping columns. \n",
    "\n",
    "In the prior example, we could have written:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_2.join(right_2, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` `,join()` method performs a left join on the join keys (mostly for legacy reasons in much earlier versions of pandas). It also supports joining the index of the passed `DataFrame` on one of the columns of the calling `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_1.join(right_1, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, for simple index-on-index merges, you can pass a list of `DataFrames` to join as an alternative to using the more general concat function described below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [16., 17.]],\n",
    "                    index=['a', 'c', 'e', 'f'], columns=['New York', 'Oregon'])\n",
    "left_2.join([right_2, another])\n",
    "left_2.join([right_2, another], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.3 Combining and Mergind Data Sets: Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (17): </b>\n",
    "\n",
    "<p>1. Define two dataframes:</p>\n",
    "\n",
    "**df1 = pd.DataFrame({'employee': ['Emma', 'George', 'Lisa', 'Olivia'],\n",
    "                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})**\n",
    "                    \n",
    "**df2 = pd.DataFrame({'employee': ['Emma', 'Olivia', 'Jacob', 'George','Lisa'],\n",
    "    'hire_date': [2004, 2008, 2012, 2014,2009]})**\n",
    "    \n",
    "<p>2. Combine the two dataframes. The expected output is: </p>\n",
    "<img src=\"//i.imgur.com/MIT5PDl.png\" height=\"30%\" width=\"30%\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (18): </b>\n",
    "\n",
    "<p>Combine the dataframes <b>df1</b> and <b>df2</b> defined in Exercise 1. The expected output is: </p>\n",
    "<img src=\"//i.imgur.com/9vhABls.png\" height=\"30%\" width=\"30%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (19): </b>\n",
    "\n",
    "<p>1. Define two dataframes:</p>\n",
    "\n",
    "**df1 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                           'A': ['A0', 'A1', 'A2', 'A3'],'B': ['B0', 'B1', 'B2', 'B3']})**\n",
    "\n",
    "**df2 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                           'C': ['C0', 'C1', 'C2', 'C3'],'D': ['D0', 'D1', 'D2', 'D3']})**\n",
    "    \n",
    "<p>2. Combine the two dataframes. The data from <b>df1</b> should be kept in the new dataframe. The expected output is:</p>\n",
    "<img src=\"//i.imgur.com/8miA1nl.png\" height=\"30%\" width=\"30%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (20): </b>\n",
    "\n",
    "<p>1. Define two dataframes:</p>\n",
    "\n",
    "**df1=DataFrame({'key1':['foo','foo','bar','bar'],\n",
    "                 'key2':['one','one','one','two'],\n",
    "                 'lval':[4,5,6,7]})**\n",
    "\n",
    "**df2=DataFrame({'key3':['foo','foo','bar'],\n",
    "                'key4':['one','two','one'],\n",
    "                'lval':[1,2,3]})**\n",
    "\n",
    "<p>2. Combine the two dataframes. The expected output is:</p>\n",
    "<img src=\"//i.imgur.com/60F7pZn.png\" height=\"30%\" width=\"30%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10 Concatenating Along an Axis \n",
    "\n",
    "Another kind of data combination operation is alternatively referred to as **concatenation**, binding, or stacking. **`NumPy`** has a concatenate function for doing this with raw NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = np.arange(12).reshape((3, 4))\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2 = np.concatenate([arr, arr], axis=1)\n",
    "arr_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of **`Pandas`** objects such as `Series` and `DataFrame`, having labeled axes enable you to further generalize array concatenation. In particular, you have a number of additional things to think about:\n",
    "\n",
    "- If the objects are indexed differently on the other axes, should the collection of axes be unioned or intersected?\n",
    "- Do the groups need to be identifiable in the resulting object?\n",
    "- Does the concatenation axis matter at all?\n",
    "\n",
    "The `concat` function in `Pandas` provides a consistent way to address each of these concerns. We will give a number of examples to illustrate how it works. Suppose we have three `Series` with no index overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([0, 1], index=['a', 'b'])\n",
    "s2 = pd.Series([2, 3, 4], index=['c', 'd', 'e'])\n",
    "s3 = pd.Series([5, 6], index=['f', 'g'])\n",
    "print(s1)\n",
    "print(s2)\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `concat` with these object in a list glues together the values and indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([s1, s2, s3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default `concat` works along `axis=0`, producing another `Series`. If you pass `axis=1`, the result will instead be a `DataFrame` (`axis=1` is the columns). In this case there is no overlap on the other axis, which as you can see is the sorted union (the 'outer' join) of the indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([s1, s2, s3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can intersect them by passing `join='inner'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s4 = pd.concat([s1 * 5, s3])\n",
    "print(pd.concat([s1, s4], axis=1))\n",
    "pd.concat([s1, s4], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One issue is that the concatenated pieces are not identifiable in the result. Suppose instead you wanted to create a hierarchical index on the concatenation axis. To do this, use the keys argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([s1, s1, s3], keys=['one', 'two', 'three'])\n",
    "result \n",
    "result.unstack() # Much more on the unstack function later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of combining `Series` along `axis=1`, the keys become the `DataFrame` column headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([s1, s2, s3], axis=1, keys=['one', 'two', 'three'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same logic extends to `DataFrame` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(6).reshape(3, 2), index=['a', 'b', 'c'], columns=['one', 'two'])\n",
    "df2 = pd.DataFrame(5 + np.arange(4).reshape(2, 2), index=['a', 'c'], columns=['three', 'four'])\n",
    "pd.concat([df1, df2], axis=1, keys=['level1', 'level2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass a dict of objects instead of a list, the dict’s keys will be used for the keys option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat({'level1': df1, 'level2': df2}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of additional arguments governing how the hierarchical index is created: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=1, keys=['level1', 'level2'],\n",
    "          names=['upper', 'lower'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A last consideration concerns `DataFrames` in which the row index is not meaningful in the context of the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.random.randn(3, 4), columns=['a', 'b', 'c', 'd'])\n",
    "df2 = pd.DataFrame(np.random.randn(2, 3), columns=['b', 'd', 'a'])\n",
    "print(df1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, you can pass `ignore_index=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`concat` **function arguments**\n",
    "\n",
    "| **Arguments** | **Description** |\n",
    "| --- | --- |\n",
    "| `objs` | List or dict of **`Pandas`** objects to be concatenated. The only required argument |\n",
    "| `axis` | Axis to concatenate along; defaults to 0 |\n",
    "| `join` | One of **inner**, **outer**, defaulting to **outer**; whether to intersection (inner) or union (outer) together indexes along the other axes |\n",
    "| `join_axis` | Specific indexes to use for the other $n-1$ axes instead of performing union/intersection logic |\n",
    "| `keys` | Values to associate with objects being concatenated, forming a hierarchical index along the concatenation axis. Can either be a list or array of arbitrary values, an array of tuples, or a list of arrays (if multiple level arrays passed in `levels`) |\n",
    "| `levels` | Specific indexes to use as hierarchical index level or levels if keys passed |\n",
    "| `names` | Names for created hierarchical levels if `keys` and / or `levels` passed |\n",
    "| `verify_integrity` | Check new axis in concatenated object for duplicates and raise exception if so. By default (`False`) allows duplicates |\n",
    "| `ignore_index` | Do not preserve indexes along concatenation `axis`, instead producing a new `range(total_length)` index |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11 Combining Data with `overlap`\n",
    "\n",
    "Another data combination situation can’t be expressed as either a *merge* or *concatenation* operation. You may have two datasets whose indexes overlap in full or part. As a motivating example, consider the **`NumPy`** `where` function, which expressed a vectorized if-else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series([np.nan, 2.5, np.nan, 3.5, 4.5, np.nan], index=['f', 'e', 'd', 'c', 'b', 'a'])\n",
    "b = pd.Series(np.arange(len(a), dtype=np.float64), index=['f', 'e', 'd', 'c', 'b', 'a'])\n",
    "b[-1] = np.nan\n",
    "print(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(pd.isnull(a), b, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Series` has a `.combine_first()` method, which performs the equivalent of this operation plus data alignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[:-2].combine_first(a[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `DataFrame`, `.combine_first()` naturally does the same thing column by column, so you can think of it as “patching” missing data in the calling object with data from the object you pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'a': [1., np.nan, 5., np.nan], \n",
    "                 'b': [np.nan, 2., np.nan, 6.],\n",
    "                 'c': range(2, 18, 4)})\n",
    "df2 = pd.DataFrame({'a': [5., 4., np.nan, 3., 7.], \n",
    "                 'b': [np.nan, 3., 4., 6., 8.]})\n",
    "df1.combine_first(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11.1 Combining Data wityh `overlap`: Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (21): </b>\n",
    "\n",
    "<p>1. Define two dataframes:</p>\n",
    "\n",
    "**df1 = DataFrame({'city': ['Chicago', 'San Francisco', 'New York City'], 'rank': range(1, 4)})**\n",
    "\n",
    "**df2 = DataFrame({'city': ['Chicago', 'Boston', 'Los Angeles'], 'rank': [1, 4, 5]})**\n",
    "    \n",
    "<p>2. Concatenate the two dataframes. The expected output is:</p>\n",
    "<img src=\"//i.imgur.com/V0nutRc.png\" height=\"30%\" width=\"30%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (22): </b>\n",
    "\n",
    "<p>Concatenate the two dataframes defined in Exercise (21). The expected output is:</p>\n",
    "<img src=\"//i.imgur.com/6PHyKor.png\" height=\"20%\" width=\"20%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (23): </b>\n",
    "<p>Concatenate the two dataframes defined in Exercise (21). The expected output is:</p>\n",
    "<img src=\"//i.imgur.com/tNoIebC.png\" height=\"20%\" width=\"20%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (24): </b>\n",
    "\n",
    "<p>1. Define two dataframes:</p>\n",
    "\n",
    "**df1 = DataFrame({'city': ['Chicago', 'San Francisco', 'New York City'], 'rank': range(1, 4)})**\n",
    "\n",
    "**df2 = DataFrame({'city': ['Chicago', 'Boston', 'Los Angeles'], 'rank': [1, 4, 5]})**\n",
    "    \n",
    "<p>2. Concatenate the two dataframes. The expected output is:</p>\n",
    "<img src=\"//i.imgur.com/AylE54E.png\" height=\"30%\" width=\"30%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (25): </b>\n",
    "\n",
    "<p>1. Define two dataframes:</p>\n",
    "\n",
    "**df1 = pd.DataFrame([[np.nan, 3., 5.], [-4.6, np.nan, np.nan],[np.nan, 7., np.nan]])**\n",
    "\n",
    "**df2 = pd.DataFrame([[-42.6, -7.7, -8.2], [-5., 1.6, 4]], index=[1, 2])**\n",
    "    \n",
    "<p>2. Fill in the missing data in <b>df1</b> with data from <b>df2</b>. The expected output is:</p>\n",
    "<img src=\"//i.imgur.com/seWo2n9.png\" height=\"20%\" width=\"20%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.12 Reshaping\n",
    "\n",
    "There are a number of fundamental operations for rearranging tabular data. These are alternatingly referred to as reshape or pivot operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.12.1 Reshaping with Hierarchical Indexing \n",
    "\n",
    "Hierarchical indexing provides a consistent way to rearrange data in a `DataFrame`. \n",
    "\n",
    "There are two primary actions:\n",
    "- `.stack()`: this “rotates” or pivots from the columns in the data to the rows\n",
    "- `.unstack()`: this pivots from the rows into the columns\n",
    "\n",
    "We can illustrate these operations through a series of examples. \n",
    "\n",
    "Consider a small `DataFrame` with string arrays as row and column indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.DataFrame(np.arange(6).reshape((2, 3)),\n",
    "                index=pd.Index(['Ohio', 'Colorado'], name='state'),\n",
    "                columns=pd.Index(['one', 'two', 'three'], name='number'))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `.stack()` method on this data pivots the columns into the rows, producing a `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data.stack()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a hierarchically-indexed `Series`, you can rearrange the data back into a `DataFrame` with `.unstack()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the innermost level is unstacked (same with `.stack()`). You can unstack a different level by passing a level number or name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.unstack(0))\n",
    "result.unstack('state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unstacking might introduce missing data if all of the values in the level aren’t found in each of the subgroups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([0, 1, 2, 3], index=['a', 'b', 'c', 'd'])\n",
    "s2 = pd.Series([4, 5, 6], index=['c', 'd', 'e'])\n",
    "data2 = pd.concat([s1, s2], keys=['one', 'two'])\n",
    "data2.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking filters out missing data by default, so the operation is easily invertible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data2.unstack().stack())\n",
    "data2.unstack().stack(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When unstacking in a `DataFrame`, the level unstacked becomes the lowest level in the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'left': result, 'right': result + 5}, columns=pd.Index(['left', 'right'], name='side'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.unstack('state'))\n",
    "df.unstack('state').stack('side')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.12.2 Reshaping: Exrecises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (26): </b>\n",
    "\n",
    "<p>1. Use the **df** dataframe:</p>\n",
    "\n",
    "**df = DataFrame({'left': result, 'right': result + 5}, columns=pd.Index(['left', 'right'], name='side'))**\n",
    "\n",
    "<p>2. Unstack the **df** and the name of the axis to stack is side.</p>\n",
    "\n",
    "<p>3. The expected output should look as follows:</p>\n",
    "<img src=\"//i.imgur.com/GxKOrM1.png\" style=\"max-width: 100%; min-height: 233px;\">\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.13 Data Transformation \n",
    "\n",
    "So far we’ve been concerned with rearranging data. \n",
    "\n",
    "Filtering, cleaning, and other tranformations are another class of important operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.13.1 Removing Duplicates \n",
    "\n",
    "Duplicate rows may be found in a `DataFrame` for any number of reasons. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'k1': ['one'] * 3 + ['two'] * 4,\n",
    "                  'k2': [1, 1, 2, 3, 3, 4, 4]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataFrame` method `.duplicated()` returns a boolean `Series` indicating whether each row is a duplicate or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatedly, `.drop_duplicates()` returns a `DataFrame` where the duplicated array is `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these methods by default consider all of the columns; alternatively you can specify any subset of them to detect duplicates. Suppose we had an additional column of values and wanted to filter duplicates only based on the `k1` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['v1'] = range(7)\n",
    "data.drop_duplicates(['k1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.duplicated()` and `.drop_duplicates()` by default keep the first observed value combination. Passing `take_last=True` will return the last one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(['k1', 'k2'], keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.13.2 Transforming Data Using a Function or Mapping\n",
    "\n",
    "For many data sets, you may wish to perform some transformation based on the values in an array, `Series`, or column in a `DataFrame`. Consider the following hypothetical data collected about some kinds of meat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon', 'Pastrami', \n",
    "                           'corned beef', 'Bacon', 'pastrami', 'honey ham',\n",
    "                           'nova lox'],\n",
    "                  'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted to add a column indicating the type of animal that each food came from.\n",
    "\n",
    "Let’s write down a mapping of each distinct meat type to the kind of animal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_to_animal = { 'bacon': 'pig', \n",
    "                  'pulled pork': 'pig', \n",
    "                  'pastrami': 'cow', \n",
    "                  'corned beef': 'cow', \n",
    "                  'honey ham': 'pig', \n",
    "                  'nova lox': 'salmon'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.map()` method on a `Series` accepts a function or dict-like object containing a mapping, but here we have a small problem in that some of the meats above are capitalized and others are not.Thus, we also need to convert each value to lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['animal'] = data['food'].map(str.lower).map(meat_to_animal)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also have passed a function that does all the work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['food'].map(lambda x: meat_to_animal[x.lower()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `.map()` is a convenient way to perform element-wise transformations and other data cleaning-related operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.13.3 Data Transformation: Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (27): </b>\n",
    "\n",
    "<p>1. Use the <b>data</b> dataframe:</p>\n",
    "\n",
    "**raw_data = {'first_name': ['Jason', 'Jason', 'Tina', 'Jake', 'Amy'], \n",
    "        'last_name': ['Miller', 'Miller','Ali', 'Milner', 'Cooze'], \n",
    "        'age': [42, 42, 36, 24, 73], \n",
    "        'preTestScore': [4, 4, 31, 2, 3],\n",
    "        'postTestScore': [25, 25, 57, 62, 70]}**\n",
    "\n",
    "**score_df = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age', 'preTestScore', 'postTestScore'])**\n",
    "    \n",
    "<p>2. The <b>score_df</b> looks as follows:</p>\n",
    "\n",
    "<img src=\"//i.imgur.com/b2d4hZv.png\" style=\"max-width: 100%; min-height: 167px;\">\n",
    "\n",
    "<p>3. Write a code which deletes the duplicate row in the dataframe <b>score_df</b>. Take the last observation in the duplicated set.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (28): </b>\n",
    "\n",
    "Write a code which multiplies each item in the list called **nums** by 2 using lamda syntax.\n",
    "\n",
    "**nums = [11,22,33]**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.14 Replacing Values\n",
    "\n",
    "Filling in missing data with the `.fillna()` method can be thought of as a special case of more general value replacement. \n",
    "\n",
    "While `.map()`, as you’ve seen above, can be used to modify a subset of values in an object, `.replace()` provides a simpler and more flexible way to do so. Let’s consider the following `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([1., -999., 2., -999., -1000., 3.])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The -999 values might be sentinel values for missing data. To replace these with `NA` values that **`Pandas`** understands, we can use replace, producing a new `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(-999, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to replace multiple values at once, you instead pass a list then the substitute value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([-999, -1000], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use a different replacement for each value, pass a list of substitutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([-999, -1000], [np.nan, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument passed can also be a dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace({-999: np.nan, -1000: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.14.1 Renaming Axis Indexes\n",
    "\n",
    "Like values in a `Series`, axis labels can be similarly transformed by a function or mapping of some form to produce new, differently labeled objects. \n",
    "\n",
    "The axes can also be modified in place without creating a new data structure. Here’s a simple example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(12).reshape((3, 4)),\n",
    "                 index=['Ohio', 'Colorado', 'New York'],\n",
    "                 columns=['one', 'two', 'three', 'four'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like a `Series`, the axis indexes have a `.map()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index.map(str.upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can assign to index, modifying the `DataFrame` in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = data.index.map(str.upper)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to create a transformed version of a data set without modifying the original, a useful method is `.rename()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(index=str.title, columns=str.upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably, `.rename()` can be used in conjunction with a dictionary-like object providing new values for a subset of the axis labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(index={'OHIO': 'INDIANA'},\n",
    "            columns={'three': 'peekaboo'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.rename()` saves having to copy the `DataFrame` manually and assign to its index and columns attributes. Should you wish to modify a data set in place, pass `inplace=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always returns a reference to a DataFrame\n",
    "_ = data.rename(index={'OHIO': 'INDIANA'}, inplace=True) \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.14.2 Discretization and Binning\n",
    "\n",
    "Continuous data is often discretized or otherwised separated into “bins” for analysis. Suppose you have data about a group of people in a study, and you want to group them into discrete age buckets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s divide these into bins of 18 to 25, 26 to 35, 35 to 60, and finally 60 and older. To do so, you have to use `cut`, a function in **`Pandas`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [18, 25, 35, 60, 100]\n",
    "cats = pd.cut(ages, bins)\n",
    "cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object **`Pandas`** returns is a special Categorical object. You can treat it like an array of strings indicating the bin name; internally it contains a `categories` array indicating the distinct category names along with a labeling for the ages data in the labels attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cats.codes)\n",
    "print(cats.categories)\n",
    "pd.value_counts(cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consistent with mathematical notation for intervals, a parenthesis means that the side is *open* while the square bracket means it is closed (inclusive). Which side is closed can be changed by passing `right=False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(ages, [18, 26, 36, 61, 100], right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass your own bin names by passing a list or array to the labels option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['Youth', 'YoungAdult', 'MiddleAged', 'Senior']\n",
    "pd.cut(ages, bins, labels=group_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass `cut` a integer number of bins instead of explicit bin edges, it will compute equal-length bins based on the minimum and maximum values in the data. \n",
    "\n",
    "Consider the case of some uniformly distributed data chopped into quarters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.rand(20)\n",
    "pd.cut(data, 4, precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A closely related function, `qcut`, bins the data based on sample quantiles. Depending on the distribution of the data, using `cut` will not usually result in each bin having the same number of data points. \n",
    "\n",
    "Since `qcut` uses sample quantiles instead, by definition you will obtain roughly equal-size bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(1000) # Normally distributed\n",
    "cats = pd.qcut(data, 4) # Cut into quartiles\n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to cut you can pass your own quantiles (numbers between 0 and 1, inclusive):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(data, [0, 0.1, 0.5, 0.9, 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll return to `cut` and `qcut` later when we look at **aggregation** and **group operations**, as these discretization functions are especially useful for quantile and group analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.14.3 Detecting and Filtering Outliers\n",
    "\n",
    "Filtering or transforming outliers is largely a matter of applying array operations. Consider a `DataFrame` with some normally distributed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "data = pd.DataFrame(np.random.randn(1000, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted to find values in one of the columns exceeding three in magnitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = data[3]\n",
    "col[np.abs(col) > 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select all rows having a value exceeding 3 or -3, you can use the `.any()` method on a Boolean `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(np.abs(data) > 3).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values can just as easily be set based on these criteria. Here is code to cap values outside the interval [-3,3] to -3 or 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[np.abs(data) > 3] = np.sign(data) * 3\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ufunc `numpy.sign` returns an array of 1 and -1 depending on the sign of the values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.14.4 Permutation and Random Sampling\n",
    "\n",
    "Permuting (randomly reordering) a `Series` or the rows in a `DataFrame` is easy to do using the `numpy.random.permutation` function. \n",
    "\n",
    "Calling permutation with the length of the axis you want to permute produces an array of integers indicating the new ordering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.arange(5 * 4).reshape(5, 4))\n",
    "sampler = np.random.permutation(5)\n",
    "sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That array can then be used in `ix-` based indexing or the take function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)\n",
    "df.take(sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select a random subset without replacement, one way is to slice off the first $k$ elements of the array returned by `permutation`, where $k$ is the desired subset size. \n",
    "\n",
    "There are much more efficient sampling-without-replacement algorithms, but this is an easy strategy that uses readily available tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.take(np.random.permutation(len(df))[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a sample with replacement, the fastest way is to use `numpy.random.randint` to draw random integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = np.array([5, 7, -1, 6, 4])\n",
    "print(bag)\n",
    "sampler = np.random.randint(0, len(bag), size=10)\n",
    "print(sampler)\n",
    "draws = bag.take(sampler)\n",
    "print(draws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.14.5 Replacing Values: Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (29): </b>\n",
    "\n",
    "Write a code which replaces the **np.nan** in **df** by 0.\n",
    "\n",
    "**df = Series([2., np.nan, 5., -999., -1000., np.nan.])**.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (30): </b> \n",
    "\n",
    "1. Use the **data** dataframe:\n",
    "\n",
    "**data = DataFrame(np.arange(12).reshape((3, 4)),\n",
    "                 index=['Ohio', 'Colorado', 'New York'],\n",
    "                 columns=['one', 'two', 'three', 'four'])**\n",
    "    \n",
    "\n",
    "2. The **data** dataframe looks as follows:\n",
    "\n",
    "<img src=\"//i.imgur.com/YJ0VMrB.png\" style=\"max-width: 100%; min-height: 114px;\">\n",
    "\n",
    "3. Write a code which transforms the column names of **data** in upper case. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (31): </b> \n",
    "\n",
    "1. Use the **data** dataframe:\n",
    "    \n",
    "**data = DataFrame(np.arange(12).reshape((3, 4)),\n",
    "                 index=['Ohio', 'Colorado', 'New York'],\n",
    "                 columns=['one', 'two', 'three', 'four'])**\n",
    "    \n",
    "\n",
    "2. The **data** dataframe looks as follows:\n",
    "<img src=\"//i.imgur.com/YJ0VMrB.png\" style=\"max-width: 100%; min-height: 114px;\">\n",
    "\n",
    "3. Write a code which transforms the row name **Colorado** of **data** to **Boston**. \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>EXERCISE (32): </b> \n",
    "\n",
    "Select all rows having a value exceeding 3.2 or -3.2 from the dataframe from Exercise (31), using the **any** method on a Boolean.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. APIs and Working with Web Applicatrions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Importing Files from the Web\n",
    "\n",
    "Let's import your first file from the web! The flat file you will import will be 'winequality-red.csv' from the **`University of California`**, **`Irvine's Machine Learning`** repository. The flat file contains tabular data of physiochemical properties of red wine, such as pH, alcohol content and citric acid content, along with wine quality rating.\n",
    "\n",
    "The URL of the file is\n",
    "\n",
    "'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "\n",
    "After you import it, you'll check your working directory to confirm that it is there and then you'll load it into a pandas DataFrame.\n",
    "\n",
    "To imported winequality-red.csv from archive.ics.uci.edu, save it locally and load it into a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "\n",
    "# Save file locally\n",
    "urlretrieve(url, './static/winequality-red.csv')\n",
    "\n",
    "# Read file into a DataFrame and print its head\n",
    "df = pd.read_csv('static/winequality-red.csv', sep=';')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you just wanted to load a file from the web into a DataFrame without first saving it locally, you can use the function `pandas.read_csv()` with the URL as the first argument and the separator sep as the second argument:\n",
    "\n",
    "The URL of the fileis:\n",
    "\n",
    "'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "\n",
    "# Read file into a DataFrame: df\n",
    "df = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Plot first column of df\n",
    "pd.DataFrame.hist(df.iloc[:, 0:1])\n",
    "plt.xlabel('Fixed Acidity (g(tartaric acid)/dm$^3$)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `pandas.read_excel()` to import an Excel spreadsheet either saved locally or from the web. For example, feeding the following URL to `pandas.read_excel()` you can read in all of its sheets, print the sheet names and print the head of the first sheet using its name, not its index.\n",
    "\n",
    "The URL of the spreadsheet is:\n",
    "\n",
    "'http://www.cse.ohio-state.edu/~hwshen/Melbourne/Data/Superstore.xlsx'\n",
    "\n",
    "Note that the output of `pandas.read_excel()` is a **`Python`** dictionary with sheet names as keys and corresponding DataFrames as corresponding values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Orders', 'Returns', 'Users'])\n",
      "   Row ID Order Priority  Discount  Unit Price  Shipping Cost  Customer ID  \\\n",
      "0   18606  Not Specified      0.01        2.88           0.50            2   \n",
      "1   20847           High      0.01        2.84           0.93            3   \n",
      "2   23086  Not Specified      0.03        6.68           6.15            3   \n",
      "3   23087  Not Specified      0.01        5.68           3.60            3   \n",
      "4   23088  Not Specified      0.00      205.99           2.50            3   \n",
      "\n",
      "     Customer Name    Ship Mode Customer Segment Product Category  ...  \\\n",
      "0  Janice Fletcher  Regular Air        Corporate  Office Supplies  ...   \n",
      "1    Bonnie Potter  Express Air        Corporate  Office Supplies  ...   \n",
      "2    Bonnie Potter  Express Air        Corporate  Office Supplies  ...   \n",
      "3    Bonnie Potter  Regular Air        Corporate  Office Supplies  ...   \n",
      "4    Bonnie Potter  Express Air        Corporate       Technology  ...   \n",
      "\n",
      "    Region State or Province       City  Postal Code Order Date  Ship Date  \\\n",
      "0  Central          Illinois    Addison        60101 2012-05-28 2012-05-30   \n",
      "1     West        Washington  Anacortes        98221 2010-07-07 2010-07-08   \n",
      "2     West        Washington  Anacortes        98221 2011-07-27 2011-07-28   \n",
      "3     West        Washington  Anacortes        98221 2011-07-27 2011-07-28   \n",
      "4     West        Washington  Anacortes        98221 2011-07-27 2011-07-27   \n",
      "\n",
      "     Profit  Quantity ordered new    Sales Order ID  \n",
      "0    1.3200                     2     5.90    88525  \n",
      "1    4.5600                     4    13.01    88522  \n",
      "2  -47.6400                     7    49.92    88523  \n",
      "3  -30.5100                     7    41.64    88523  \n",
      "4  998.2023                     8  1446.67    88523  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'http://www.cse.ohio-state.edu/~hwshen/Melbourne/Data/Superstore.xlsx'\n",
    "\n",
    "# Read in all sheets of Excel file: xl\n",
    "xl = pd.read_excel(url, sheet_name=None)\n",
    "\n",
    "# Print the sheetnames to the shell\n",
    "print(xl.keys())\n",
    "\n",
    "# Print the head of the first sheet (using its name, NOT its index)\n",
    "print(xl['Orders'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 HTTP Requests in Python\n",
    "\n",
    "To get the files directly loaded into a pandas' DataFrame, **`Pandas`** does HTTP GET requests to get the files and load them into memory. \n",
    "\n",
    "In this part of the lesson, we do our own HTTP requests. First, let's ping python.org servers to perform a GET request to extract information from:\n",
    "\n",
    "\"https://www.python.org/~guido/\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'http.client.HTTPResponse'>\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "# Specify the url\n",
    "url = \"https://www.python.org/~guido/\"\n",
    "\n",
    "# This packages the request: request\n",
    "request = Request(url)\n",
    "\n",
    "# Sends the request and catches the response: response\n",
    "response = urlopen(request)\n",
    "\n",
    "# Print the datatype of response\n",
    "print(type(response))\n",
    "\n",
    "# Be polite and close the response!\n",
    "response.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just packaged and sent a GET request to \"https://www.python.org/~guido/\" and then caught the response. \n",
    "\n",
    "The response is an `http.client.HTTPResponse` object. Since the response came from an HTML page, you could read the response to extract the HTML. The `http.client.HTTPResponse` object has an associated `.read()` method that facilitates this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<HTML>\\n\\n<HEAD>\\n<TITLE>Guido\\'s Personal Home Page</TITLE>\\n</HEAD>\\n\\n<BODY BGCOLOR=\"#FFFFFF\" TEXT=\"#000000\">\\n\\n<!-- Built from main -->\\n<H1>\\n<a href=\"pics.html\"><img border=\"0\" src=\"images/IMG_2192.jpg\"></a>\\nGuido van Rossum - Personal Home Page\\n<a href=\"pics.html\"><img border=0 width=270 height=216 src=\"images/guido-headshot-2019.jpg\"></a>\\n</H1>\\n\\n<P><A\\nHREF=\"http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\" \\n><i>\"Gawky and proud of it.\"</i></A>\\n\\n\\n<H3><a href=\"images/df20000406.jpg\" >Who I Am</a></H3>\\n\\n<p>Read\\nmy <a href=\"http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\">\"King\\'s\\nDay Speech\"</a> for some inspiration.\\n\\n<P>I am the author of the <A HREF=\"http://www.python.org\" >Python</A>\\nprogramming language.  See also my <A HREF=\"Resume.html\">resume</A>\\nand my <A HREF=\"Publications.html\">publications list</A>, a <A\\nHREF=\"bio.html\" >brief bio</A>, assorted <a\\nhref=\"http://legacy.python.org/doc/essays/\">writings</a>, <a\\nhref=\"http://legacy.python.org/doc/essays/ppt/\">presentations</a> and <a\\nhref=\"interviews.html\">interviews</a> (all about Python), some\\n<a href=\"pics.html\">pictures of me</a>,\\n<a href=\"http://neopythonic.blogspot.com\">my new blog</a>, and\\nmy <a href=\"http://www.artima.com/weblogs/index.jsp?blogger=12088\">old\\nblog</a> on Artima.com.  I am\\n<a href=https://twitter.com/gvanrossum>@gvanrossum</a> on Twitter.\\n\\n<p>I am currently a Distinguished Engineer at Microsoft.\\nI have worked for Dropbox, Google, Elemental Security, Zope\\nCorporation, BeOpen.com, CNRI, CWI, and SARA.  (See\\nmy <a href=Resume.html>resume</a>.)  I created Python while at CWI.\\n\\n<H3>How to Reach Me</H3>\\n\\n<P>You can send email for me to guido (at) python.org.\\nI read everything sent there, but I receive too much email to respond\\nto everything.\\n\\n<P>Please understand that I do not give talks or keynotes any more,\\nnor do I participate in podcasts or give interviews, etc.\\nI am sorry, but I just receive too many such requests to decline\\nthem individually.\\nOffering payment or trips to exotic locales just makes things worse, sorry.\\n\\n<P>I also prefer not to receive questions about how to use Python\\n(please read the <a href=\"https://docs.python.org\">documentation</a> or search the internet for Python answers forums),\\nbug reports (use the <a href=\"https://github.com/python/cpython/issues\">GitHub issue tracker</a>),\\nproposals for changes to the language (use <a href=\"https://discuss.python.org\">Discourse</a>),\\njob offers (I\\'m happy where I am),\\nor requests to join you in some far-fetched scheme to save humanity (though sometimes I like me a good rant :-).\\n\\n<H3>My Name</H3>\\n\\n<P>My name often poses difficulties for Americans.\\n\\n<P><b>Pronunciation:</b> in Dutch, the \"G\" in Guido is a hard G,\\npronounced roughly like the \"ch\" in Scottish \"loch\".  (Listen to the\\n<A HREF=\"guido.au\">sound clip</A>.)  However, if you\\'re\\nAmerican, you may also pronounce it as the Italian \"Guido\".  I\\'m not\\ntoo worried about the associations with mob assassins that some people\\nhave. :-)\\n\\n<P><b>Spelling:</b> my last name is two words, and I\\'d like to keep it\\nthat way, the spelling on some of my credit cards notwithstanding.\\nDutch spelling rules dictate that when used in combination with my\\nfirst name, \"van\" is not capitalized: \"Guido van Rossum\".  But when my\\nlast name is used alone to refer to me, it is capitalized, for\\nexample: \"As usual, Van Rossum was right.\"\\n\\n<P><b>Alphabetization:</b> in America, I show up in the alphabet under\\n\"V\".  But in Europe, I show up under \"R\".  And some of my friends put\\nme under \"G\" in their address book...\\n\\n\\n<H3>More Hyperlinks</H3>\\n\\n<UL>\\n\\n<LI>Here\\'s a collection of <A HREF =\\n\"http://legacy.python.org/doc/essays/\" >essays</A> relating to Python\\nthat I\\'ve written, including the foreword I wrote for Mark Lutz\\' book\\n\"Programming Python\".<P>\\n\\n<li>I own the official <a href=\"images/license.jpg\"><img align=\"center\"\\nborder=\"0\" width=\"100\" height=\"75\" src=\"images/license_thumb.jpg\">\\nPython license.</a><p>\\n\\n</UL>\\n\\n<H3>The Audio File Formats FAQ</H3>\\n\\n<P>I was the original creator and maintainer of the Audio File Formats\\nFAQ.  It is now maintained by Chris Bagwell\\nat <A HREF=\"http://www.cnpbagwell.com/audio-faq\"\\n>http://www.cnpbagwell.com/audio-faq</A>.  And here is a link to\\n<a href=http://sox.sourceforge.net/>SOX</a>, to which I contributed\\nsome early code.\\n\\n</UL>\\n\\n<HR>\\n\\n<A HREF=\"images/internetdog.gif\">\"On the Internet, nobody knows you\\'re\\na dog.\"</A>\\n\\n<HR>\\n\\n</BODY>\\n'\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "# Specify the url\n",
    "url = \"https://www.python.org/~guido/\"\n",
    "\n",
    "# This packages the request\n",
    "request = Request(url)\n",
    "\n",
    "# Sends the request and catches the response: response\n",
    "response = urlopen(request)\n",
    "\n",
    "# Extract the response: html\n",
    "html = response.read()\n",
    "\n",
    "# Print the html\n",
    "print(html)\n",
    "\n",
    "# Be polite and close the response!\n",
    "response.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 HTTP Requests Using **`requests`**\n",
    "\n",
    "There are different libraries in Python to handle HTTP requests. `requests` is a higher-level requests library. With*`requests`, you don't have to close the connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HTML>\n",
      "\n",
      "<HEAD>\n",
      "<TITLE>Guido's Personal Home Page</TITLE>\n",
      "</HEAD>\n",
      "\n",
      "<BODY BGCOLOR=\"#FFFFFF\" TEXT=\"#000000\">\n",
      "\n",
      "<!-- Built from main -->\n",
      "<H1>\n",
      "<a href=\"pics.html\"><img border=\"0\" src=\"images/IMG_2192.jpg\"></a>\n",
      "Guido van Rossum - Personal Home Page\n",
      "<a href=\"pics.html\"><img border=0 width=270 height=216 src=\"images/guido-headshot-2019.jpg\"></a>\n",
      "</H1>\n",
      "\n",
      "<P><A\n",
      "HREF=\"http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\" \n",
      "><i>\"Gawky and proud of it.\"</i></A>\n",
      "\n",
      "\n",
      "<H3><a href=\"images/df20000406.jpg\" >Who I Am</a></H3>\n",
      "\n",
      "<p>Read\n",
      "my <a href=\"http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\">\"King's\n",
      "Day Speech\"</a> for some inspiration.\n",
      "\n",
      "<P>I am the author of the <A HREF=\"http://www.python.org\" >Python</A>\n",
      "programming language.  See also my <A HREF=\"Resume.html\">resume</A>\n",
      "and my <A HREF=\"Publications.html\">publications list</A>, a <A\n",
      "HREF=\"bio.html\" >brief bio</A>, assorted <a\n",
      "href=\"http://legacy.python.org/doc/essays/\">writings</a>, <a\n",
      "href=\"http://legacy.python.org/doc/essays/ppt/\">presentations</a> and <a\n",
      "href=\"interviews.html\">interviews</a> (all about Python), some\n",
      "<a href=\"pics.html\">pictures of me</a>,\n",
      "<a href=\"http://neopythonic.blogspot.com\">my new blog</a>, and\n",
      "my <a href=\"http://www.artima.com/weblogs/index.jsp?blogger=12088\">old\n",
      "blog</a> on Artima.com.  I am\n",
      "<a href=https://twitter.com/gvanrossum>@gvanrossum</a> on Twitter.\n",
      "\n",
      "<p>I am currently a Distinguished Engineer at Microsoft.\n",
      "I have worked for Dropbox, Google, Elemental Security, Zope\n",
      "Corporation, BeOpen.com, CNRI, CWI, and SARA.  (See\n",
      "my <a href=Resume.html>resume</a>.)  I created Python while at CWI.\n",
      "\n",
      "<H3>How to Reach Me</H3>\n",
      "\n",
      "<P>You can send email for me to guido (at) python.org.\n",
      "I read everything sent there, but I receive too much email to respond\n",
      "to everything.\n",
      "\n",
      "<P>Please understand that I do not give talks or keynotes any more,\n",
      "nor do I participate in podcasts or give interviews, etc.\n",
      "I am sorry, but I just receive too many such requests to decline\n",
      "them individually.\n",
      "Offering payment or trips to exotic locales just makes things worse, sorry.\n",
      "\n",
      "<P>I also prefer not to receive questions about how to use Python\n",
      "(please read the <a href=\"https://docs.python.org\">documentation</a> or search the internet for Python answers forums),\n",
      "bug reports (use the <a href=\"https://github.com/python/cpython/issues\">GitHub issue tracker</a>),\n",
      "proposals for changes to the language (use <a href=\"https://discuss.python.org\">Discourse</a>),\n",
      "job offers (I'm happy where I am),\n",
      "or requests to join you in some far-fetched scheme to save humanity (though sometimes I like me a good rant :-).\n",
      "\n",
      "<H3>My Name</H3>\n",
      "\n",
      "<P>My name often poses difficulties for Americans.\n",
      "\n",
      "<P><b>Pronunciation:</b> in Dutch, the \"G\" in Guido is a hard G,\n",
      "pronounced roughly like the \"ch\" in Scottish \"loch\".  (Listen to the\n",
      "<A HREF=\"guido.au\">sound clip</A>.)  However, if you're\n",
      "American, you may also pronounce it as the Italian \"Guido\".  I'm not\n",
      "too worried about the associations with mob assassins that some people\n",
      "have. :-)\n",
      "\n",
      "<P><b>Spelling:</b> my last name is two words, and I'd like to keep it\n",
      "that way, the spelling on some of my credit cards notwithstanding.\n",
      "Dutch spelling rules dictate that when used in combination with my\n",
      "first name, \"van\" is not capitalized: \"Guido van Rossum\".  But when my\n",
      "last name is used alone to refer to me, it is capitalized, for\n",
      "example: \"As usual, Van Rossum was right.\"\n",
      "\n",
      "<P><b>Alphabetization:</b> in America, I show up in the alphabet under\n",
      "\"V\".  But in Europe, I show up under \"R\".  And some of my friends put\n",
      "me under \"G\" in their address book...\n",
      "\n",
      "\n",
      "<H3>More Hyperlinks</H3>\n",
      "\n",
      "<UL>\n",
      "\n",
      "<LI>Here's a collection of <A HREF =\n",
      "\"http://legacy.python.org/doc/essays/\" >essays</A> relating to Python\n",
      "that I've written, including the foreword I wrote for Mark Lutz' book\n",
      "\"Programming Python\".<P>\n",
      "\n",
      "<li>I own the official <a href=\"images/license.jpg\"><img align=\"center\"\n",
      "border=\"0\" width=\"100\" height=\"75\" src=\"images/license_thumb.jpg\">\n",
      "Python license.</a><p>\n",
      "\n",
      "</UL>\n",
      "\n",
      "<H3>The Audio File Formats FAQ</H3>\n",
      "\n",
      "<P>I was the original creator and maintainer of the Audio File Formats\n",
      "FAQ.  It is now maintained by Chris Bagwell\n",
      "at <A HREF=\"http://www.cnpbagwell.com/audio-faq\"\n",
      ">http://www.cnpbagwell.com/audio-faq</A>.  And here is a link to\n",
      "<a href=http://sox.sourceforge.net/>SOX</a>, to which I contributed\n",
      "some early code.\n",
      "\n",
      "</UL>\n",
      "\n",
      "<HR>\n",
      "\n",
      "<A HREF=\"images/internetdog.gif\">\"On the Internet, nobody knows you're\n",
      "a dog.\"</A>\n",
      "\n",
      "<HR>\n",
      "\n",
      "</BODY>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Specify the url: url\n",
    "url = \"https://www.python.org/~guido/\"\n",
    "\n",
    "# Packages the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extract the response: text\n",
    "text = r.text\n",
    "\n",
    "# Print the html\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 API Requests\n",
    "\n",
    "\n",
    "An **API** is a set of definitions and protocols for building and integrating application software. API stands for application programming interface.\n",
    "\n",
    "APIs let your product or service communicate with other products and services without having to know how they’re implemented. This can simplify app development, saving time and money. When you’re designing new tools and products—or managing existing ones—APIs give you flexibility; simplify design, administration, and use; and provide opportunities for innovation.\n",
    "\n",
    "APIs are sometimes thought of as contracts, with documentation that represents an agreement between parties: If party 1 sends a remote request structured a particular way, this is how party 2’s software will respond.\n",
    "\n",
    "Web APIs typically use HTTP for request messages and provide a definition of the structure of response messages. These response messages usually take the form of an XML or JSON file. Both XML and JSON are preferred formats because they present data in a way that’s easy for other apps to manipulate.\n",
    "\n",
    "As defined by: [redhat.com](https://www.redhat.com/en/topics/api/what-are-application-programming-interfaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two major standards for APIs are:\n",
    "\n",
    "- **SOAP** (Simple Object Access Protocol) is an interface to communicate and exchange data over HTTP and SMTP using structured data XML (Extensible Markup Language)\n",
    "- **REST** (Representational State Transfer)\n",
    "\n",
    "Web APIs that adhere to the REST architectural constraints are called RESTful APIs. REST differs from SOAP in a fundamental way: SOAP is a protocol, whereas REST is an architectural style. This means that there’s no official standard for RESTful web APIs ([redhat.com](https://www.redhat.com/en/topics/api/what-are-application-programming-interfaces)).\n",
    "\n",
    "Since **REST APIs** are the most popular APIs and they realy on the JSON data format to send and receive messages, we are going to first explore how to load a JSON file, which **`Python`** interprets as a dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings:  [{'Source': 'Internet Movie Database', 'Value': '7.7/10'}, {'Source': 'Rotten Tomatoes', 'Value': '95%'}, {'Source': 'Metacritic', 'Value': '95/100'}]\n",
      "Country:  USA\n",
      "imdbVotes:  550,434\n",
      "Rated:  PG-13\n",
      "Plot:  Harvard student Mark Zuckerberg creates the social networking site that would become known as Facebook, but is later sued by two brothers who claimed he stole their idea, and the co-founder who was later squeezed out of the business.\n",
      "Genre:  Biography, Drama\n",
      "Response:  True\n",
      "Released:  01 Oct 2010\n",
      "Language:  English, French\n",
      "DVD:  11 Jan 2011\n",
      "Poster:  https://m.media-amazon.com/images/M/MV5BMTM2ODk0NDAwMF5BMl5BanBnXkFtZTcwNTM1MDc2Mw@@._V1_SX300.jpg\n",
      "Production:  Columbia Pictures\n",
      "Director:  David Fincher\n",
      "Title:  The Social Network\n",
      "imdbRating:  7.7\n",
      "Writer:  Aaron Sorkin (screenplay), Ben Mezrich (book)\n",
      "Year:  2010\n",
      "Metascore:  95\n",
      "Type:  movie\n",
      "Runtime:  120 min\n",
      "Website:  http://www.thesocialnetwork-movie.com/\n",
      "imdbID:  tt1285016\n",
      "Actors:  Jesse Eisenberg, Rooney Mara, Bryan Barter, Dustin Fitzsimons\n",
      "Awards:  Won 3 Oscars. Another 165 wins & 168 nominations.\n",
      "BoxOffice:  $96,400,000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON: json_data\n",
    "with open(\"./static/a_movie.json\") as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "# Print each key-value pair in json_data\n",
    "for k in json_data.keys():\n",
    "    print(k + ': ', json_data[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 API Request With Authentication\n",
    "\n",
    "Let's make an API requests to the **`Open Movie Database`** (OMDB) to search for the movie \"The Social Network\":\n",
    "\n",
    "- Import the requests package.\n",
    "- The URL to query is: \n",
    "        'http://www.omdbapi.com'\n",
    "- The Open Movie Database (OMDB) requires to provide to register for an `apikey` to use their RESTful web service. You can register [here](https://www.omdbapi.com/apikey.aspx).\n",
    "- The query string should have two arguments: `apikey=your_api_key` and `t=movie+name`. You can combine them as follows:\n",
    "`apikey=72bc447a&t=the+social+network`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Title\":\"The Social Network\",\"Year\":\"2010\",\"Rated\":\"PG-13\",\"Released\":\"01 Oct 2010\",\"Runtime\":\"120 min\",\"Genre\":\"Biography, Drama\",\"Director\":\"David Fincher\",\"Writer\":\"Aaron Sorkin, Ben Mezrich\",\"Actors\":\"Jesse Eisenberg, Andrew Garfield, Justin Timberlake\",\"Plot\":\"As Harvard student Mark Zuckerberg creates the social networking site that would become known as Facebook, he is sued by the twins who claimed he stole their idea and by the co-founder who was later squeezed out of the business.\",\"Language\":\"English, French\",\"Country\":\"United States\",\"Awards\":\"Won 3 Oscars. 173 wins & 186 nominations total\",\"Poster\":\"https://m.media-amazon.com/images/M/MV5BOGUyZDUxZjEtMmIzMC00MzlmLTg4MGItZWJmMzBhZjE0Mjc1XkEyXkFqcGdeQXVyMTMxODk2OTU@._V1_SX300.jpg\",\"Ratings\":[{\"Source\":\"Internet Movie Database\",\"Value\":\"7.8/10\"},{\"Source\":\"Rotten Tomatoes\",\"Value\":\"96%\"},{\"Source\":\"Metacritic\",\"Value\":\"95/100\"}],\"Metascore\":\"95\",\"imdbRating\":\"7.8\",\"imdbVotes\":\"737,649\",\"imdbID\":\"tt1285016\",\"Type\":\"movie\",\"DVD\":\"05 Jun 2012\",\"BoxOffice\":\"$96,962,694\",\"Production\":\"N/A\",\"Website\":\"N/A\",\"Response\":\"True\"}\n"
     ]
    }
   ],
   "source": [
    "# Import requests package\n",
    "import requests\n",
    "\n",
    "# Method 1:\n",
    "url = 'http://www.omdbapi.com?apikey=72bc447a&t=the+social+network'\n",
    "r = requests.get(url)\n",
    "\n",
    "# Method 2:\n",
    "url = \"http://www.omdbapi.com\"\n",
    "params = {\"apikey\":\"72bc447a\", \"t\":\"the social network\"}\n",
    "r = requests.get(url, params=params)\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we just printed the text of the HTTP response. The response is actually a JSON, so you can do one step better and decode the JSON data into a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  The Social Network\n",
      "Year:  2010\n",
      "Rated:  PG-13\n",
      "Released:  01 Oct 2010\n",
      "Runtime:  120 min\n",
      "Genre:  Biography, Drama\n",
      "Director:  David Fincher\n",
      "Writer:  Aaron Sorkin, Ben Mezrich\n",
      "Actors:  Jesse Eisenberg, Andrew Garfield, Justin Timberlake\n",
      "Plot:  As Harvard student Mark Zuckerberg creates the social networking site that would become known as Facebook, he is sued by the twins who claimed he stole their idea and by the co-founder who was later squeezed out of the business.\n",
      "Language:  English, French\n",
      "Country:  United States\n",
      "Awards:  Won 3 Oscars. 173 wins & 186 nominations total\n",
      "Poster:  https://m.media-amazon.com/images/M/MV5BOGUyZDUxZjEtMmIzMC00MzlmLTg4MGItZWJmMzBhZjE0Mjc1XkEyXkFqcGdeQXVyMTMxODk2OTU@._V1_SX300.jpg\n",
      "Ratings:  [{'Source': 'Internet Movie Database', 'Value': '7.8/10'}, {'Source': 'Rotten Tomatoes', 'Value': '96%'}, {'Source': 'Metacritic', 'Value': '95/100'}]\n",
      "Metascore:  95\n",
      "imdbRating:  7.8\n",
      "imdbVotes:  737,649\n",
      "imdbID:  tt1285016\n",
      "Type:  movie\n",
      "DVD:  05 Jun 2012\n",
      "BoxOffice:  $96,962,694\n",
      "Production:  N/A\n",
      "Website:  N/A\n",
      "Response:  True\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url\n",
    "url = 'http://www.omdbapi.com/?apikey=72bc447a&t=social+network'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Decode the JSON data into a dictionary: json_data\n",
    "json_data = r.json()\n",
    "\n",
    "# Print each key-value pair in json_data\n",
    "for k in json_data.keys():\n",
    "    print(k + ': ', json_data[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 API Request Without Authentication\n",
    "\n",
    "The Open Movie Database (OMDB) returned a simple JSON. However, there are other APIs that are going to return nested JSONs, that is, JSONs within JSONs, but Python can handle that because it will translate them into dictionaries within dictionaries.\n",
    "\n",
    "For example, let's make a request to the Wikipedia API searching for \"University College London\"\n",
    "The URL that requests the relevant query from the Wikipedia API is:\n",
    "    \n",
    "    - https://en.wikipedia.org/w/api.php?action=query&prop=extracts&format=json&exintro=&titles=University+College+London\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"mw-empty-elt\">\n",
      "\n",
      "\n",
      "</p>\n",
      "<p><b>University College London</b>, which operates as <b>UCL</b>, is a public research university in London, England. It is a member institution of the federal University of London, and is the second-largest university in the United Kingdom by total enrolment and the largest by postgraduate enrolment.\n",
      "</p><p>Established in 1826 as <b>London University</b> (though without university degree-awarding powers) by founders inspired by the radical ideas of Jeremy Bentham, UCL was the first university institution to be established in London, and the first in England to be entirely secular and to admit students regardless of their religion. It was also among the first university colleges to admit women alongside men in 1878, two years after University College, Bristol. Intended by its founders to be England's third university, politics forced it to accept the status of a college in 1836, when it received a royal charter and became one of the two founding colleges of the University of London, although it achieved <i>de facto</i> recognition as a university in the 1990s and formal university status in 2023. It has grown through mergers, including with the Institute of Ophthalmology (in 1995), the Institute of Neurology (in 1997), the Royal Free Hospital Medical School (in 1998), the Eastman Dental Institute (in 1999), the School of Slavonic and East European Studies (in 1999), the School of Pharmacy (in 2012) and the Institute of Education (in 2014).\n",
      "</p><p>UCL has its main campus in the Bloomsbury area of central London, with a number of institutes and teaching hospitals elsewhere in central London and has a second campus, UCL East, at Queen Elizabeth Olympic Park in Stratford, East London. UCL is organised into 11 constituent faculties, within which there are over 100 departments, institutes and research centres. UCL operates several museums and collections in a wide range of fields, including the Petrie Museum of Egyptian Archaeology and the Grant Museum of Zoology and Comparative Anatomy, and administers the annual Orwell Prize in political writing. In 2021/22, UCL had a total income of £1.75 billion, of which £525 million was from research grants and contracts. The university generates around £10 billion annually for the UK economy, primarily through the spread of its research and knowledge (£4 billion) and the impact of its own spending (£3 billion).</p><p>UCL is a member of numerous academic organisations, including the Russell Group and the League of European Research Universities, and is part of UCL Partners, the world's largest academic health science centre. It is considered part of the \"golden triangle\" of research-intensive universities in southeast England. UCL has publishing and commercial activities including UCL Press, UCL Business and UCL Consultants.\n",
      "</p><p>UCL has many notable alumni, including the founder of Mauritius, the first Prime Minister of Japan, one of the co-discoverers of the structure of DNA, and Coldplay members. UCL academics discovered five of the naturally occurring noble gases, discovered hormones, invented the vacuum tube, and made several foundational advances in modern statistics. As of 2022, 30 Nobel Prize winners and three Fields medallists have been affiliated with UCL as alumni or academic staff.\n",
      "</p>\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url\n",
    "url = \"https://en.wikipedia.org/w/api.php?action=query&prop=extracts&format=json&exintro=&titles=University+College+London\"\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Decode the JSON data into a dictionary: json_data\n",
    "json_data = r.json()\n",
    "\n",
    "# Print the Wikipedia page extract\n",
    "wikipedia_extract = json_data['query']['pages']['52029']['extract']\n",
    "print(wikipedia_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Credits </h1>\n",
    "\n",
    "- [Online Python Tutor: Embeddable Web-Based Program Visualization for CS Education](http://pythontutor.com/), Philip J. Guo, ACM Technical Symposium on Computer Science Education (SIGCSE), 2013\n",
    "\n",
    "\n",
    "- Machine Learning Algorithms from Scratch with Python, 2017, Jason Brownlee, v1.2\n",
    "\n",
    "\n",
    "- An introduction to Python Programming for Research, UCL, 2017, James Hetherington [here:](http://rits.github-pages.ucl.ac.uk/doctoral-programming-intro/notes.pdf)\n",
    "\n",
    "\n",
    "- A Primer on Scientific Programming with Python, 4th Edition, 2014, Hans Petter Langtangen \n",
    "Resources [here:](http://hplgit.github.io/scipro-primer/)\n",
    "\n",
    "\n",
    "- [W3C's Web Services Architecture](https://www.w3.org/TR/ws-arch/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
